{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Théo\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. Collaborative filtering\n",
    "3. **Content-based filtering (you are here)**\n",
    "4. _Appendix_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 - Content-based filtering\n",
    "In the previous notebook, we tested different collaborative filtering models, and we saw that they had very bad scores. We will now try another filtering technique. Content-based filtering uses item features to recommend other items to what the user likes. In our case, we use a user's previous ratings and try to suggest items that are similar to the animes he rated the highest.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Data preparation</li>\n",
    "  <li>The \"Nearest Neighbors\" model</li>\n",
    "  <li>Conclusion of the content-based filtering</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "from pathlib import Path\n",
    "\n",
    "# Math\n",
    "import numpy\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore\n",
    "\n",
    "# Misc.\n",
    "from ast import literal_eval"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2 - Package initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3 - Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4 - Datasets loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_anime = pandas.read_csv(DATA_FOLDER / \"anime_cleaned.csv\", converters={\"genre_split\": literal_eval})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B - Data preparation\n",
    "The previous systems were using a collaborative filtering technique. These models were trained on a dataset containing a user identifier, an item identifier and a rating. No further processing were required. But in this notebook, we will use the content-based technique.\n",
    "\n",
    "This technique uses the characteristics of the item itself to build recommandation, instead of interactions between users and items. While it cannot be used to get the last trending item, it is very useful to find similar items.\n",
    "\n",
    "For this technique to work, we must first translate some values to a format that can be interpreted by the model. In this section, we will go through the preparation of the data and explain why we do this. These transformations were not done in the first pre-processing, as some transformations make the data less usable with the plotting libraries (e.g. one-hot encoding)\n",
    "\n",
    "### B.1 - Filtering out some columns\n",
    "We start the preparation by filtering out some of the columns that are not used in the research of similarities such as identifiers, ranks, ... Usually, we would keep the name of the anime as it constitute the `y`, the labels that we want to predict. But in this case, it is simple research of close items, and the name doesn't have a purpose in this situation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   genre   type  episodes  \\\n0                   Drama, Romance, School, Supernatural  Movie         1   \n1      Action, Adventure, Drama, Fantasy, Magic, Mili...     TV        64   \n2      Action, Comedy, Historical, Parody, Samurai, S...     TV        51   \n3                                       Sci-Fi, Thriller     TV        24   \n4      Action, Comedy, Historical, Parody, Samurai, S...     TV        51   \n...                                                  ...    ...       ...   \n12289                                             Hentai    OVA         1   \n12290                                             Hentai    OVA         1   \n12291                                             Hentai    OVA         4   \n12292                                             Hentai    OVA         1   \n12293                                             Hentai  Movie         1   \n\n       rating  members  num_ratings  \n0        9.37   200630         1961  \n1        9.26   793665        21494  \n2        9.25   114262         1188  \n3        9.17   673572        17151  \n4        9.16   151266         3115  \n...       ...      ...          ...  \n12289    4.15      211            2  \n12290    4.28      183            2  \n12291    4.88      219            1  \n12292    4.98      175            1  \n12293    5.46      142            0  \n\n[12294 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating</th>\n      <th>members</th>\n      <th>num_ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Drama, Romance, School, Supernatural</td>\n      <td>Movie</td>\n      <td>1</td>\n      <td>9.37</td>\n      <td>200630</td>\n      <td>1961</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n      <td>TV</td>\n      <td>64</td>\n      <td>9.26</td>\n      <td>793665</td>\n      <td>21494</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.25</td>\n      <td>114262</td>\n      <td>1188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sci-Fi, Thriller</td>\n      <td>TV</td>\n      <td>24</td>\n      <td>9.17</td>\n      <td>673572</td>\n      <td>17151</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.16</td>\n      <td>151266</td>\n      <td>3115</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12289</th>\n      <td>Hentai</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.15</td>\n      <td>211</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12290</th>\n      <td>Hentai</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.28</td>\n      <td>183</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12291</th>\n      <td>Hentai</td>\n      <td>OVA</td>\n      <td>4</td>\n      <td>4.88</td>\n      <td>219</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12292</th>\n      <td>Hentai</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.98</td>\n      <td>175</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12293</th>\n      <td>Hentai</td>\n      <td>Movie</td>\n      <td>1</td>\n      <td>5.46</td>\n      <td>142</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12294 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed = data_anime.drop(labels=[\"anime_id\", \"name\", \"genre_split\", \"rank_avg_rating\", \"rank_num_ratings\"], axis=1, inplace=False)\n",
    "data_preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B.2 - Encoding and standardization\n",
    "The next step is to encode the text values.\n",
    "\n",
    "Usually we would use `scikit-learn` and its internal encoders to do the job, but the `genre` column is incompatible with those. So we will encode this column using `pandas` and `scikit-learn` will take care of the rest.\n",
    "\n",
    "There is two techniques to encode strings: one-hot encoding and label encoding.\n",
    "\n",
    "Label encoding is a technique for handling categorical variables. In this technique, each label is assigned a unique integer number based on alphabetical order. The main problem with this technique is that it creates a kind of ranking between categories. The model might interpret a higher integer as a better value. This type of encoding works well with ordinal features or when there are a large number of categories.\n",
    "\n",
    "One-hot encoding is another technique for transforming categorical variables. It creates additional features (columns in the case of a dataframe) based on the number of unique values in the categorical features. Each possible value is represented by a new feature with two possible values: 0 or 1. This technique solves the label encoding problem, but it creates another one. We must be careful not to fall into the dummy variable trap. A dummy variable trap occurs when two categories have a very high correlation. For example, \"single\" and \"divorced\" are very close and the model could interpret these two categories as being the same, but in fact they are very different. In contrast to label encoding, one-hot encoding performs better on non-ordinal features and when the number of categories remains low.\n",
    "\n",
    "The most sensible choice in our case is the one-hot encoding."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       genre_Action  genre_Adventure  genre_Cars  genre_Comedy  \\\n0                 0                0           0             0   \n1                 1                1           0             0   \n2                 1                0           0             1   \n3                 0                0           0             0   \n4                 1                0           0             1   \n...             ...              ...         ...           ...   \n12289             0                0           0             0   \n12290             0                0           0             0   \n12291             0                0           0             0   \n12292             0                0           0             0   \n12293             0                0           0             0   \n\n       genre_Dementia  genre_Demons  genre_Drama  genre_Ecchi  genre_Fantasy  \\\n0                   0             0            1            0              0   \n1                   0             0            1            0              1   \n2                   0             0            0            0              0   \n3                   0             0            0            0              0   \n4                   0             0            0            0              0   \n...               ...           ...          ...          ...            ...   \n12289               0             0            0            0              0   \n12290               0             0            0            0              0   \n12291               0             0            0            0              0   \n12292               0             0            0            0              0   \n12293               0             0            0            0              0   \n\n       genre_Game  ...  genre_Thriller  genre_Unknown  genre_Vampire  \\\n0               0  ...               0              0              0   \n1               0  ...               0              0              0   \n2               0  ...               0              0              0   \n3               0  ...               1              0              0   \n4               0  ...               0              0              0   \n...           ...  ...             ...            ...            ...   \n12289           0  ...               0              0              0   \n12290           0  ...               0              0              0   \n12291           0  ...               0              0              0   \n12292           0  ...               0              0              0   \n12293           0  ...               0              0              0   \n\n       genre_Yaoi  genre_Yuri   type  episodes  rating  members  num_ratings  \n0               0           0  Movie         1    9.37   200630         1961  \n1               0           0     TV        64    9.26   793665        21494  \n2               0           0     TV        51    9.25   114262         1188  \n3               0           0     TV        24    9.17   673572        17151  \n4               0           0     TV        51    9.16   151266         3115  \n...           ...         ...    ...       ...     ...      ...          ...  \n12289           0           0    OVA         1    4.15      211            2  \n12290           0           0    OVA         1    4.28      183            2  \n12291           0           0    OVA         4    4.88      219            1  \n12292           0           0    OVA         1    4.98      175            1  \n12293           0           0  Movie         1    5.46      142            0  \n\n[12294 rows x 49 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genre_Action</th>\n      <th>genre_Adventure</th>\n      <th>genre_Cars</th>\n      <th>genre_Comedy</th>\n      <th>genre_Dementia</th>\n      <th>genre_Demons</th>\n      <th>genre_Drama</th>\n      <th>genre_Ecchi</th>\n      <th>genre_Fantasy</th>\n      <th>genre_Game</th>\n      <th>...</th>\n      <th>genre_Thriller</th>\n      <th>genre_Unknown</th>\n      <th>genre_Vampire</th>\n      <th>genre_Yaoi</th>\n      <th>genre_Yuri</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating</th>\n      <th>members</th>\n      <th>num_ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Movie</td>\n      <td>1</td>\n      <td>9.37</td>\n      <td>200630</td>\n      <td>1961</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>TV</td>\n      <td>64</td>\n      <td>9.26</td>\n      <td>793665</td>\n      <td>21494</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.25</td>\n      <td>114262</td>\n      <td>1188</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>TV</td>\n      <td>24</td>\n      <td>9.17</td>\n      <td>673572</td>\n      <td>17151</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>TV</td>\n      <td>51</td>\n      <td>9.16</td>\n      <td>151266</td>\n      <td>3115</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>12289</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.15</td>\n      <td>211</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12290</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.28</td>\n      <td>183</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12291</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>OVA</td>\n      <td>4</td>\n      <td>4.88</td>\n      <td>219</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12292</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>OVA</td>\n      <td>1</td>\n      <td>4.98</td>\n      <td>175</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12293</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Movie</td>\n      <td>1</td>\n      <td>5.46</td>\n      <td>142</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12294 rows × 49 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_col_idx = data_preprocessed.columns.get_loc(\"genre\")\n",
    "\n",
    "# We use this technique to preserve the column order\n",
    "data_preprocessed = pandas.concat(objs=[\n",
    "    data_preprocessed.iloc[:, :genre_col_idx],  # All columns before the `gender` column\n",
    "    data_preprocessed[\"genre\"].str.get_dummies(sep=\", \").add_prefix(\"genre_\"),  #  One-hot encoded genders\n",
    "    data_preprocessed.iloc[:, (genre_col_idx + 1):]  # All columns after the `gender` column\n",
    "], axis=1, ignore_index=False, sort=False)\n",
    "data_preprocessed"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is now possible to use `scikit-learn` to encode and normalize the rest of the dataset. We first complete the one-hot encoding with the last text column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "categorical_features = [\"type\"]\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    # Put the SimpleImputer here in case of missing data\n",
    "    (\"encoder\", OneHotEncoder(categories=\"auto\", handle_unknown=\"error\"))\n",
    "], verbose=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we standardize numerical columns.\n",
    "\n",
    "Standardization is a technique that changes the range of values without affecting the shape of the data and by reducing the standard deviation to one. This pre-processing is necessary in order to produce a powerful model. In our case, the `num_ratings` column would have a much higher weight on the predictions than the `rating` column. But a large number of ratings does not necessarily mean that it is the best recommendation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "numeric_features = [\"episodes\", \"rating\", \"members\", \"num_ratings\"]\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    # Put the SimpleImputer here in case of missing data\n",
    "    (\"scaler\", StandardScaler())\n",
    "], verbose=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Usually, the pipeline would have a simple imputer to fill in the missing data. But we have already solved this problem before during the data exploration, so we don't need it.\n",
    "\n",
    "The final step is to initialize the column transformer and to fit the dataset on it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ColumnTransformer] ... (1 of 3) Processing categorical, total=   0.0s\n",
      "[ColumnTransformer] ....... (2 of 3) Processing numeric, total=   0.0s\n",
      "[ColumnTransformer] ....... (3 of 3) Processing skipped, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ColumnTransformer\n",
    "genre_cols = [column for column in data_preprocessed if column.startswith(\"genre_\")]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"categorical\", categorical_transformer, categorical_features),\n",
    "        (\"numeric\", numeric_transformer, numeric_features),\n",
    "        (\"skipped\", \"passthrough\", genre_cols)  # We skip the pre-processing of the gender columns but keep them.\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit and transform the dataset\n",
    "features_x = preprocessor.fit_transform(data_preprocessed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can save the transformed dataset to disk for later use."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "numpy.save(file=str(DATA_FOLDER / \"x-anime_16-03-23_11-25\"), arr=features_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And reload it with this block of code."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [1., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_x = numpy.load(file=str(DATA_FOLDER / \"x-anime_16-03-23_11-25.npy\"))\n",
    "features_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we explained before, this kind of data is nearly unusable during the data exploration. This is the reason why we are doing it now."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## C - The \"Nearest Neighbors\" model\n",
    "In this section, we will define a model that will give ten close items for each anime in the dataset.\n",
    "\n",
    "### C.1 - Model definition and similarities computation\n",
    "From the [sklearn docs](https://scikit-learn.org/stable/modules/neighbors.html), [NearestNeighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors) implements unsupervised nearest neighbors learning. It acts as a uniform interface to three different nearest neighbors algorithms: [BallTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.BallTree.html#sklearn.neighbors.BallTree), [KDTree](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KDTree.html#sklearn.neighbors.KDTree), and a brute-force algorithm based on routines in `sklearn.metrics.pairwise`. When the algorithm is set to `\"auto\"`, the module attempts to determine the best `algorithm` from the training data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "NearestNeighbors(metric='cosine', n_neighbors=11)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=11)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=11)</pre></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NearestNeighbors(n_neighbors=11, radius=1.0, algorithm=\"auto\", metric=\"cosine\")\n",
    "model.fit(features_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may notice that we define the `n_neighbors` parameter to `11`. This is caused by the fact that the first item of the neighbors list will always be the item itself. We will filter this one out later, but we still need ten other items to be in this list. We're using the `cosine` metric because it is one of the best option when we want to compute similarities between items.\n",
    "\n",
    "We can now compute the similarities."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "distances, indices = model.kneighbors(features_x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### C.2 - Getting the Top-N\n",
    "We normally don't need the rating dataset. But in our case, we want to get the top ten of a user using his identifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "data_ratings = pandas.read_csv((DATA_FOLDER / \"rating.csv\"), dtype={\"user_id\": int, \"anime_id\": int, \"rating\": float})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we use the ratings dataset to get one of the best rated anime of a user and display other anime close to this one."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def get_best_rated_anime(user_id: int, df_ratings: pandas.DataFrame, df_animes: pandas.DataFrame) -> int | None:\n",
    "    \"\"\"\n",
    "        Returns the index of the best rated anime by this user.\n",
    "        **It does NOT return the anime identifier, only the index relative to the DataFrame.**\n",
    "        It may return None if the user has no rating.\n",
    "    \"\"\"\n",
    "    user_ratings = df_ratings.loc[df_ratings[\"user_id\"] == user_id]\n",
    "    user_ratings = user_ratings[user_ratings[\"rating\"] >= 0]\n",
    "\n",
    "    if len(user_ratings) == 0:  # If the user hasn't rated any item\n",
    "        return None\n",
    "    else:  # Get the best rated item\n",
    "        user_ratings.sort_values(by=\"rating\", ascending=False)\n",
    "        user_ratings = user_ratings.loc[user_ratings[\"rating\"] == max(user_ratings[\"rating\"])]\n",
    "        random_item = user_ratings.sample(n=1).iloc[0]\n",
    "\n",
    "        return int(df_animes.index[df_animes[\"anime_id\"] == random_item[\"anime_id\"]].tolist()[0])\n",
    "\n",
    "\n",
    "def get_top_n_of(user_id: int, df: pandas.DataFrame, df_ratings: pandas.DataFrame, indices_arr: numpy.ndarray) -> pandas.DataFrame:\n",
    "    anime_idx = get_best_rated_anime(user_id=user_id, df_ratings=df_ratings, df_animes=df)\n",
    "\n",
    "    if anime_idx is not None:\n",
    "        related_anime = []\n",
    "\n",
    "        for related_anime_idx in indices_arr[anime_idx][1:]:\n",
    "            related_anime.append(df.iloc[related_anime_idx].to_dict())\n",
    "\n",
    "        return pandas.DataFrame(related_anime)\n",
    "    else:\n",
    "        print(f\"{Fore.YELLOW}Cannot build the Top-N: The user has not rated any anime.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We pick a random user from our dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "9754"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user_id = int(data_ratings.sample(n=1).iloc[0][\"user_id\"])\n",
    "random_user_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And we display his top-N."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "   anime_id                                name  \\\n0      1698                    Nodame Cantabile   \n1     21995                        Ao Haru Ride   \n2      4722                          Skip Beat!   \n3      1222                       Bokura ga Ita   \n4       120                       Fruits Basket   \n5        57                                Beck   \n6      3731                     Itazura na Kiss   \n7     18671  Chuunibyou demo Koi ga Shitai! Ren   \n8     11433                Ano Natsu de Matteru   \n9      2034                      Lovely★Complex   \n\n                                               genre  \\\n0  Comedy, Drama, Josei, Music, Romance, Slice of...   \n1  Comedy, Drama, Romance, School, Shoujo, Slice ...   \n2                     Comedy, Drama, Romance, Shoujo   \n3              Drama, Romance, Shoujo, Slice of Life   \n4  Comedy, Drama, Fantasy, Romance, Shoujo, Slice...   \n5       Comedy, Drama, Music, Shounen, Slice of Life   \n6                            Comedy, Romance, Shoujo   \n7      Comedy, Drama, Romance, School, Slice of Life   \n8      Comedy, Drama, Romance, Sci-Fi, Slice of Life   \n9                            Comedy, Romance, Shoujo   \n\n                                         genre_split type  episodes  rating  \\\n0  [Comedy, Drama, Josei, Music, Romance, Slice o...   TV        23    8.46   \n1  [Comedy, Drama, Romance, School, Shoujo, Slice...   TV        12    7.89   \n2                   [Comedy, Drama, Romance, Shoujo]   TV        25    8.28   \n3            [Drama, Romance, Shoujo, Slice of Life]   TV        26    7.54   \n4  [Comedy, Drama, Fantasy, Romance, Shoujo, Slic...   TV        26    7.80   \n5     [Comedy, Drama, Music, Shounen, Slice of Life]   TV        26    8.40   \n6                          [Comedy, Romance, Shoujo]   TV        25    7.76   \n7    [Comedy, Drama, Romance, School, Slice of Life]   TV        12    7.60   \n8    [Comedy, Drama, Romance, Sci-Fi, Slice of Life]   TV        12    7.70   \n9                          [Comedy, Romance, Shoujo]   TV        24    8.23   \n\n   members  num_ratings  rank_avg_rating  rank_num_ratings  \n0   157025         4616            156.0             318.0  \n1   227417         5547            790.5             239.0  \n2   134818         4893            285.0             290.0  \n3   125051         3912           1598.5             395.0  \n4   242553         9171            955.0              93.0  \n5   148328         4963            189.5             285.0  \n6   136279         4873           1040.0             292.0  \n7   208885         5817           1426.0             223.0  \n8   169718         5171           1176.0             271.0  \n9   235003         8293            332.5             115.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>anime_id</th>\n      <th>name</th>\n      <th>genre</th>\n      <th>genre_split</th>\n      <th>type</th>\n      <th>episodes</th>\n      <th>rating</th>\n      <th>members</th>\n      <th>num_ratings</th>\n      <th>rank_avg_rating</th>\n      <th>rank_num_ratings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1698</td>\n      <td>Nodame Cantabile</td>\n      <td>Comedy, Drama, Josei, Music, Romance, Slice of...</td>\n      <td>[Comedy, Drama, Josei, Music, Romance, Slice o...</td>\n      <td>TV</td>\n      <td>23</td>\n      <td>8.46</td>\n      <td>157025</td>\n      <td>4616</td>\n      <td>156.0</td>\n      <td>318.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>21995</td>\n      <td>Ao Haru Ride</td>\n      <td>Comedy, Drama, Romance, School, Shoujo, Slice ...</td>\n      <td>[Comedy, Drama, Romance, School, Shoujo, Slice...</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.89</td>\n      <td>227417</td>\n      <td>5547</td>\n      <td>790.5</td>\n      <td>239.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4722</td>\n      <td>Skip Beat!</td>\n      <td>Comedy, Drama, Romance, Shoujo</td>\n      <td>[Comedy, Drama, Romance, Shoujo]</td>\n      <td>TV</td>\n      <td>25</td>\n      <td>8.28</td>\n      <td>134818</td>\n      <td>4893</td>\n      <td>285.0</td>\n      <td>290.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1222</td>\n      <td>Bokura ga Ita</td>\n      <td>Drama, Romance, Shoujo, Slice of Life</td>\n      <td>[Drama, Romance, Shoujo, Slice of Life]</td>\n      <td>TV</td>\n      <td>26</td>\n      <td>7.54</td>\n      <td>125051</td>\n      <td>3912</td>\n      <td>1598.5</td>\n      <td>395.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>120</td>\n      <td>Fruits Basket</td>\n      <td>Comedy, Drama, Fantasy, Romance, Shoujo, Slice...</td>\n      <td>[Comedy, Drama, Fantasy, Romance, Shoujo, Slic...</td>\n      <td>TV</td>\n      <td>26</td>\n      <td>7.80</td>\n      <td>242553</td>\n      <td>9171</td>\n      <td>955.0</td>\n      <td>93.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>57</td>\n      <td>Beck</td>\n      <td>Comedy, Drama, Music, Shounen, Slice of Life</td>\n      <td>[Comedy, Drama, Music, Shounen, Slice of Life]</td>\n      <td>TV</td>\n      <td>26</td>\n      <td>8.40</td>\n      <td>148328</td>\n      <td>4963</td>\n      <td>189.5</td>\n      <td>285.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3731</td>\n      <td>Itazura na Kiss</td>\n      <td>Comedy, Romance, Shoujo</td>\n      <td>[Comedy, Romance, Shoujo]</td>\n      <td>TV</td>\n      <td>25</td>\n      <td>7.76</td>\n      <td>136279</td>\n      <td>4873</td>\n      <td>1040.0</td>\n      <td>292.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>18671</td>\n      <td>Chuunibyou demo Koi ga Shitai! Ren</td>\n      <td>Comedy, Drama, Romance, School, Slice of Life</td>\n      <td>[Comedy, Drama, Romance, School, Slice of Life]</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.60</td>\n      <td>208885</td>\n      <td>5817</td>\n      <td>1426.0</td>\n      <td>223.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>11433</td>\n      <td>Ano Natsu de Matteru</td>\n      <td>Comedy, Drama, Romance, Sci-Fi, Slice of Life</td>\n      <td>[Comedy, Drama, Romance, Sci-Fi, Slice of Life]</td>\n      <td>TV</td>\n      <td>12</td>\n      <td>7.70</td>\n      <td>169718</td>\n      <td>5171</td>\n      <td>1176.0</td>\n      <td>271.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2034</td>\n      <td>Lovely★Complex</td>\n      <td>Comedy, Romance, Shoujo</td>\n      <td>[Comedy, Romance, Shoujo]</td>\n      <td>TV</td>\n      <td>24</td>\n      <td>8.23</td>\n      <td>235003</td>\n      <td>8293</td>\n      <td>332.5</td>\n      <td>115.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_of(user_id=random_user_id, df=data_anime, df_ratings=data_ratings, indices_arr=indices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## D - Conclusion of the content-based filtering\n",
    "This type of filtering showed us better result than in the previous notebook. This system is able to recommend a bunch of anime to a user based on those he already watched.\n",
    "\n",
    "The next notebook is the appendix. It contains the list of sources used in our research and the questions from the school subject."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
