{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Th√©o\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Collaborative filtering: unfiltered training</li>\n",
    "  <li>Collaborative filtering: filtered training</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "\n",
    "# Misc.\n",
    "from ast import literal_eval\n",
    "\n",
    "# Local files\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 - Package initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 - Datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(1, 10), skip_lines=1)\n",
    "# data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating_cleaned.csv\"), reader=data_reader)\n",
    "\n",
    "# Load a smaller sample of the dataset instead of the 8M rows\n",
    "data_cleaned = pandas.read_csv((DATA_FOLDER / \"rating_cleaned.csv\"))\n",
    "data_filtered = data_cleaned[data_cleaned[\"rating\"] >= 0.0]\n",
    "data_shortened = data_filtered.sample(n=35_000)\n",
    "\n",
    "data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(df=data_shortened[[\"user_id\", \"anime_id\", \"rating\"]], reader=data_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Collaborative filtering: unfiltered training\n",
    "expliquer collaborative filtering\n",
    "expliquer diff. user-based/item-based\n",
    "\n",
    "## B.2 - Slope One\n",
    "expliquer slope one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"Slope One\".\u001B[39m\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [ train = 0.0000 | test = 1.8406 ]\n",
      "\u001B[1mMAE:\u001B[22m [ train = 0.0000 | test = 1.5102 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 0.000000%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 0.000000%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0\n",
      "\u001B[1mUser coverage (num_users=7, min_rating=4.0):\u001B[22m 100.000000%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Item 8795 is not part of the trainset.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/trainset.py:155\u001B[0m, in \u001B[0;36mTrainset.to_inner_iid\u001B[0;34m(self, riid)\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw2inner_id_items\u001B[49m\u001B[43m[\u001B[49m\u001B[43mriid\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n",
      "\u001B[0;31mKeyError\u001B[0m: '8795'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model_slope_one, _, top_n_slope_one \u001B[38;5;241m=\u001B[39m \u001B[43mhelpers\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mml\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mSlope One\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msurprise\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSlopeOne\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhyper_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodels_folder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mMODELS_FOLDER\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRANDOM_STATE\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/mnt/c/Users/alexi/Desktop/Cours-IA/5MLRE/Project/notebooks/en/../../helpers/ml.py:91\u001B[0m, in \u001B[0;36mrun_model\u001B[0;34m(name, model, dataset, hyper_params, measures, measure_key, models_folder, seed)\u001B[0m\n\u001B[1;32m     88\u001B[0m     grid_search_start_time \u001B[38;5;241m=\u001B[39m grid_search_end_time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;66;03m# Accuracy calculation\u001B[39;00m\n\u001B[0;32m---> 91\u001B[0m top_n, model_start_time, model_end_time \u001B[38;5;241m=\u001B[39m \u001B[43mcompute_metrics\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbest_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbest_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mseed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;66;03m# Save the model to the disk\u001B[39;00m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m models_folder:\n",
      "File \u001B[0;32m/mnt/c/Users/alexi/Desktop/Cours-IA/5MLRE/Project/notebooks/en/../../helpers/ml.py:160\u001B[0m, in \u001B[0;36mcompute_metrics\u001B[0;34m(model, dataset, best_params, seed)\u001B[0m\n\u001B[1;32m    158\u001B[0m     metrics\u001B[38;5;241m.\u001B[39mget_average_reciprocal_hit_rank(top_n\u001B[38;5;241m=\u001B[39mtop_n, left_out_predictions\u001B[38;5;241m=\u001B[39mleft_out_predictions, auto_print\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    159\u001B[0m     metrics\u001B[38;5;241m.\u001B[39mget_user_coverage(top_n\u001B[38;5;241m=\u001B[39mtop_n, num_users\u001B[38;5;241m=\u001B[39mdata_train_LOOCV\u001B[38;5;241m.\u001B[39mn_users, min_rating\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4.0\u001B[39m, auto_print\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 160\u001B[0m     \u001B[43mmetrics\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_diversity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtop_n\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtop_n\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mauto_print\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m top_n, model_start_time, model_end_time\n",
      "File \u001B[0;32m/mnt/c/Users/alexi/Desktop/Cours-IA/5MLRE/Project/notebooks/en/../../helpers/metrics.py:196\u001B[0m, in \u001B[0;36mget_diversity\u001B[0;34m(top_n, model, auto_print)\u001B[0m\n\u001B[1;32m    194\u001B[0m item1 \u001B[38;5;241m=\u001B[39m pair[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    195\u001B[0m item2 \u001B[38;5;241m=\u001B[39m pair[\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m--> 196\u001B[0m inner_id1 \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrainset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_inner_iid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mitem1\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    197\u001B[0m inner_id2 \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrainset\u001B[38;5;241m.\u001B[39mto_inner_iid(\u001B[38;5;28mstr\u001B[39m(item2))\n\u001B[1;32m    199\u001B[0m similarity \u001B[38;5;241m=\u001B[39m similarities_matrix[inner_id1][inner_id2]\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/trainset.py:157\u001B[0m, in \u001B[0;36mTrainset.to_inner_iid\u001B[0;34m(self, riid)\u001B[0m\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raw2inner_id_items[riid]\n\u001B[1;32m    156\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m:\n\u001B[0;32m--> 157\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mItem \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(riid) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is not part of the trainset.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: Item 8795 is not part of the trainset."
     ]
    }
   ],
   "source": [
    "model_slope_one, _, top_n_slope_one = helpers.ml.run_model(\n",
    "    name=\"Slope One\",\n",
    "    model=surprise.SlopeOne,\n",
    "    dataset=data,\n",
    "    hyper_params=None,\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.2 - KNN Basic\n",
    "expliquer KNN Basic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_knn_basic, _, top_n_knn_basic = helpers.ml.run_model(\n",
    "    name=\"KNN Basic\",\n",
    "    model=surprise.KNNBasic,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.3 - KNN With Means\n",
    "expliquer KNN With Means"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_knn_with_means, _, top_n_knn_with_means = helpers.ml.run_model(\n",
    "    name=\"KNN With Means\",\n",
    "    model=surprise.KNNWithMeans,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.4 - KNN With Z-Score\n",
    "expliquer KNN With Z-Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_knn_with_z_score, _, top_n_knn_with_z_score = helpers.ml.run_model(\n",
    "    name=\"KNN With Z-Score\",\n",
    "    model=surprise.KNNWithZScore,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.5 - KNN Baseline\n",
    "expliquer KNN Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_knn_baseline, _, top_n_knn_baseline = helpers.ml.run_model(\n",
    "    name=\"KNN Baseline\",\n",
    "    model=surprise.KNNBaseline,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        },\n",
    "        \"bsl_options\": {\n",
    "            \"method\": [\"als\"],\n",
    "            \"n_epochs\": [5, 10, 15],\n",
    "        }\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.6 - Non-negative Matrix Factorization\n",
    "expliquer Non-negative Matrix Factorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_nmf, _, top_n_nmf = helpers.ml.run_model(\n",
    "    name=\"Non-negative Matrix Factorization\",\n",
    "    model=surprise.NMF,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"n_factors\": [5, 15, 25],\n",
    "        \"n_epochs\": [25, 50, 75],\n",
    "        \"biased\": [True, False]\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.7 - Co-clustering\n",
    "expliquer Co-clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_co_clustering, _, top_n_co_clustering = helpers.ml.run_model(\n",
    "    name=\"Co-clustering\",\n",
    "    model=surprise.CoClustering,\n",
    "    dataset=data,\n",
    "    hyper_params={\n",
    "        \"n_cltr_u\": [1, 3, 5],\n",
    "        \"n_cltr_i\": [1, 3, 5],\n",
    "        \"n_epochs\": [10, 20, 30],\n",
    "    },\n",
    "    models_folder=MODELS_FOLDER,\n",
    "    seed=RANDOM_STATE\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.8 - Comparing performance\n",
    "**TODO**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "_, model_nmf = surprise.dump.load(file_name=str(MODELS_FOLDER / \"Non-negative Matrix Factorization\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B.9 - Getting the Top-N\n",
    "**TODO**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data_anime = pandas.read_csv(DATA_FOLDER / \"anime_cleaned.csv\", converters={\"genre_split\": literal_eval})"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
