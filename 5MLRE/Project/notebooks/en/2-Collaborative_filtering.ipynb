{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Th√©o\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Data preparation</li>\n",
    "  <li>Collaborative filtering: user-based</li>\n",
    "  <li>Collaborative filtering: item-based</li>\n",
    "  <li>Collaborative filtering: others</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "from surprise import accuracy as surp_acc\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Jupyter output\n",
    "from IPython.utils import io\n",
    "\n",
    "# Local files\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "import helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2 - Package initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3 - Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4 - Datasets loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(1, 10), skip_lines=1)\n",
    "# data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating_cleaned.csv\"), reader=data_reader)\n",
    "\n",
    "data = pandas.read_csv((DATA_FOLDER / \"rating_cleaned.csv\"))\n",
    "data_filtered = data[data[\"rating\"] >= 0.0]\n",
    "data_shortened = data.sample(n=10_000)\n",
    "\n",
    "data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(df=data_shortened, reader=data_reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B - Data preparation\n",
    "**TODO: Add text**\n",
    "\n",
    "### B.1 - Splitting the dataset\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# data_train, data_test = surprise.model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "data_train_full = data.build_full_trainset()\n",
    "data_test = data_train_full.build_testset()\n",
    "data_anti_test = data_train_full.build_anti_testset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B.2 - Choosing the data iterator\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_iterator = surprise.model_selection.KFold(n_splits=10, random_state=RANDOM_STATE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C - Collaborative filtering\n",
    "expliquer diff. user-based/item-based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_definitions = {\n",
    "    \"slope_one\": {\n",
    "        \"name\": \"Slope One\",\n",
    "        \"algo_class\": surprise.SlopeOne,\n",
    "        \"hyper_params\": None\n",
    "    },\n",
    "    \"knn_basic\": {\n",
    "        \"name\": \"KNN Basic\",\n",
    "        \"algo_class\": surprise.KNNBasic,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_means\": {\n",
    "        \"name\": \"KNN With Means\",\n",
    "        \"algo_class\": surprise.KNNWithMeans,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_z-score\": {\n",
    "        \"name\": \"KNN With Z-Score\",\n",
    "        \"algo_class\": surprise.KNNWithZScore,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_baseline\": {\n",
    "        \"name\": \"KNN Baseline\",\n",
    "        \"algo_class\": surprise.KNNBaseline,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            },\n",
    "            \"bsl_options\": {\n",
    "                \"method\": [\"als\"],\n",
    "                \"n_epochs\": 10,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"non-negative_matrix_factorization\": {\n",
    "        \"name\": \"Non-negative Matrix Factorization\",\n",
    "        \"algo_class\": surprise.NMF,\n",
    "        \"hyper_params\": {\n",
    "            \"n_factors\": [5, 15, 25],\n",
    "            \"n_epochs\": [25, 50, 75],\n",
    "            \"biased\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"co-clustering\": {\n",
    "        \"name\": \"Co-clustering\",\n",
    "        \"algo_class\": surprise.CoClustering,\n",
    "        \"hyper_params\": {\n",
    "            \"n_cltr_u\": [1, 3, 5],\n",
    "            \"n_cltr_i\": [1, 3, 5],\n",
    "            \"n_epochs\": [10, 20, 30],\n",
    "        }\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mTesting multiple models...\u001B[0m\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"Slope One\".\u001B[39m\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Style.BRIGHT}Testing multiple models...{Style.RESET_ALL}\")\n",
    "model_sep = f\"{Style.DIM}{Fore.WHITE}{'=' * 25}{Style.RESET_ALL}\"\n",
    "measure_key = \"rmse\"\n",
    "best_models = {}\n",
    "\n",
    "for model_key in model_definitions:\n",
    "    # Initialize the model processing\n",
    "    iteration_start_time = timer()\n",
    "    model_settings = model_definitions[model_key]\n",
    "    print(f\"{model_sep}\\n{Fore.GREEN}Testing \\\"{model_settings['name']}\\\".{Fore.RESET}\")\n",
    "\n",
    "    # Train the model\n",
    "    model_start_time = timer()\n",
    "    if model_settings[\"hyper_params\"] is not None:  # If available, search the best estimator with GridSearch\n",
    "        print(f\"Running GridSearchCV...{Fore.WHITE}{Style.DIM}\")\n",
    "        grid_search_start_time = timer()\n",
    "        with io.capture_output():\n",
    "            grid_search = surprise.model_selection.GridSearchCV(\n",
    "                algo_class=model_settings[\"algo_class\"],\n",
    "                param_grid=model_settings[\"hyper_params\"],\n",
    "                measures=[\"rmse\", \"mae\"],\n",
    "                cv=data_iterator,\n",
    "                refit=False,\n",
    "                n_jobs=1,\n",
    "                joblib_verbose=0\n",
    "            )\n",
    "            grid_search.fit(data)\n",
    "\n",
    "        best_model = grid_search.best_estimator[measure_key]\n",
    "        best_params = grid_search.best_params[measure_key]\n",
    "        grid_search_end_time = timer()\n",
    "    else:\n",
    "        best_model = model_settings[\"algo_class\"]()\n",
    "        best_params = []\n",
    "        grid_search_start_time = grid_search_end_time = None\n",
    "\n",
    "    # Save the best model\n",
    "    best_models[model_key] = best_model\n",
    "\n",
    "    # Accuracy calculation\n",
    "    model_start_time = timer()\n",
    "    best_model.fit(data_train_full)\n",
    "    left_out_predictions = best_model.test(data_test)\n",
    "    all_predictions = best_model.test(data_anti_test)\n",
    "    model_end_time = timer()\n",
    "\n",
    "    print(f\"{Style.RESET_ALL}\")\n",
    "    print(f\"{Style.BRIGHT}Best params:{Style.NORMAL} {Style.DIM}{Fore.WHITE}{best_params}{Style.RESET_ALL}\")\n",
    "    print(f\"{Style.BRIGHT}RMSE:{Style.NORMAL} {surp_acc.rmse(left_out_predictions, verbose=False):.4f}\")\n",
    "    print(f\"{Style.BRIGHT}MAE:{Style.NORMAL} {surp_acc.mae(left_out_predictions, verbose=False):.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "    top_n = helpers.metrics.get_top_n(predictions=all_predictions, n=10, min_rating=4.0, verbose=True)\n",
    "    helpers.metrics.get_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "    helpers.metrics.get_rating_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "    helpers.metrics.get_cumulative_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, min_rating=4.0, auto_print=True)\n",
    "    helpers.metrics.get_average_reciprocal_hit_rank(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "    helpers.metrics.get_user_coverage(top_n=top_n, num_users=data_train_full.n_users, min_rating=4.0, auto_print=True)\n",
    "\n",
    "    # Final output\n",
    "    iteration_end_time = timer()\n",
    "    iteration_elapsed_time = timedelta(seconds=iteration_end_time - iteration_start_time)\n",
    "    grid_search_elapsed_time = timedelta(seconds=grid_search_end_time - grid_search_start_time) if grid_search_start_time is not None else None\n",
    "    model_elapsed_time = timedelta(seconds=model_end_time - model_start_time)\n",
    "    print((\n",
    "        f\"Testing of the \\\"{model_settings['name']}\\\" model successfully completed in {iteration_elapsed_time}.\"\n",
    "        f\"Grid search: {'N/A' if grid_search_elapsed_time is None else grid_search_elapsed_time}\"\n",
    "        f\"Training and testing: {model_elapsed_time}\"\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
