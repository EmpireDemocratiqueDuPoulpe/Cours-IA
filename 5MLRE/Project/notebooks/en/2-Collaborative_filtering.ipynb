{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Th√©o\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Data preparation</li>\n",
    "  <li>Collaborative filtering: user-based</li>\n",
    "  <li>Collaborative filtering: item-based</li>\n",
    "  <li>Collaborative filtering: others</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "from surprise import accuracy as surp_acc\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Jupyter output\n",
    "from IPython.utils import io\n",
    "\n",
    "# Local files\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 - Package initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 - Datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(1, 10), skip_lines=1)\n",
    "# data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating_cleaned.csv\"), reader=data_reader)\n",
    "\n",
    "data_cleaned = pandas.read_csv((DATA_FOLDER / \"rating_cleaned.csv\"))\n",
    "data_filtered = data_cleaned[data_cleaned[\"rating\"] >= 0.0]\n",
    "data_shortened = data_filtered.sample(n=100_000)\n",
    "\n",
    "data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(df=data_shortened[[\"user_id\", \"anime_id\", \"rating\"]], reader=data_reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Data preparation\n",
    "**TODO: Add text**\n",
    "\n",
    "### B.1 - Splitting the dataset\n",
    "**TODO: Add text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_train_full = data.build_full_trainset()\\ndata_test = data_train_full.build_testset()\\ndata_anti_test = data_train_full.build_anti_testset()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_train, data_test = surprise.model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "\"\"\"data_train_full = data.build_full_trainset()\n",
    "data_test = data_train_full.build_testset()\n",
    "data_anti_test = data_train_full.build_anti_testset()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.2 - Choosing the data iterator\n",
    "**TODO: Add text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = surprise.model_selection.KFold(n_splits=10, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C - Collaborative filtering\n",
    "expliquer diff. user-based/item-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definitions = {\n",
    "    \"slope_one\": {\n",
    "        \"name\": \"Slope One\",\n",
    "        \"algo_class\": surprise.SlopeOne,\n",
    "        \"hyper_params\": None\n",
    "    },\n",
    "    \"knn_basic\": {\n",
    "        \"name\": \"KNN Basic\",\n",
    "        \"algo_class\": surprise.KNNBasic,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_means\": {\n",
    "        \"name\": \"KNN With Means\",\n",
    "        \"algo_class\": surprise.KNNWithMeans,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_z-score\": {\n",
    "        \"name\": \"KNN With Z-Score\",\n",
    "        \"algo_class\": surprise.KNNWithZScore,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_baseline\": {\n",
    "        \"name\": \"KNN Baseline\",\n",
    "        \"algo_class\": surprise.KNNBaseline,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            },\n",
    "            \"bsl_options\": {\n",
    "                \"method\": [\"als\"],\n",
    "                \"n_epochs\": [5, 10, 15],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"non-negative_matrix_factorization\": {\n",
    "        \"name\": \"Non-negative Matrix Factorization\",\n",
    "        \"algo_class\": surprise.NMF,\n",
    "        \"hyper_params\": {\n",
    "            \"n_factors\": [5, 15, 25],\n",
    "            \"n_epochs\": [25, 50, 75],\n",
    "            \"biased\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"co-clustering\": {\n",
    "        \"name\": \"Co-clustering\",\n",
    "        \"algo_class\": surprise.CoClustering,\n",
    "        \"hyper_params\": {\n",
    "            \"n_cltr_u\": [1, 3, 5],\n",
    "            \"n_cltr_i\": [1, 3, 5],\n",
    "            \"n_epochs\": [10, 20, 30],\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mTesting multiple models...\u001B[0m\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"Slope One\".\u001B[39m\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m[]\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.0000 | test = 1.6306 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.0000 | test = 1.2816 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 25.586854%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "4.0\t28.571429%\n",
      "5.0\t36.363636%\n",
      "6.0\t10.909091%\n",
      "7.0\t17.894737%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 25.653207%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0034823443310215306\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 0.9812206572769953\n",
      "\n",
      "Testing of the \"Slope One\" model successfully completed in 0:00:01.474861.\n",
      "Grid search: N/A\n",
      "Training and testing: 0:00:01.208360\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN Basic\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': True}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.4416 | test = 1.5344 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.1633 | test = 1.2512 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 26.056338%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "4.0\t28.571429%\n",
      "5.0\t36.363636%\n",
      "6.0\t12.727273%\n",
      "7.0\t18.947368%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 26.128266%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.003495852081539578\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 1.0\n",
      "\n",
      "Testing of the \"KNN Basic\" model successfully completed in 0:02:44.174949.\n",
      "Grid search: 0:02:42.349682\n",
      "Training and testing: 0:00:01.561016\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN With Means\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': False}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.1072 | test = 1.6964 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.0231 | test = 1.3698 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 25.352113%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "5.0\t31.818182%\n",
      "6.0\t12.727273%\n",
      "7.0\t18.947368%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 25.415677%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0056793552610392125\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 1.0\n",
      "\n",
      "Testing of the \"KNN With Means\" model successfully completed in 0:03:21.973250.\n",
      "Grid search: 0:03:20.081562\n",
      "Training and testing: 0:00:01.611366\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN With Z-Score\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': False}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.1613 | test = 1.6964 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.0373 | test = 1.3698 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 25.352113%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "5.0\t31.818182%\n",
      "6.0\t12.727273%\n",
      "7.0\t18.947368%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 25.415677%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0056793552610392125\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 1.0\n",
      "\n",
      "Testing of the \"KNN With Z-Score\" model successfully completed in 0:04:59.461941.\n",
      "Grid search: 0:04:57.553892\n",
      "Training and testing: 0:00:01.636250\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN Baseline\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': True}, 'bsl_options': {'method': 'als', 'n_epochs': 5}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.4104 | test = 1.4846 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.1517 | test = 1.2044 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 26.056338%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "4.0\t28.571429%\n",
      "5.0\t36.363636%\n",
      "6.0\t12.727273%\n",
      "7.0\t18.947368%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 26.128266%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.010923151099509426\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 1.0\n",
      "\n",
      "Testing of the \"KNN Baseline\" model successfully completed in 0:08:49.294691.\n",
      "Grid search: 0:08:47.283735\n",
      "Training and testing: 0:00:01.718732\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"Non-negative Matrix Factorization\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'n_factors': 5, 'n_epochs': 25, 'biased': True}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 0.9902 | test = 1.4757 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 0.5343 | test = 1.2040 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 26.056338%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "4.0\t28.571429%\n",
      "5.0\t36.363636%\n",
      "6.0\t12.727273%\n",
      "7.0\t18.947368%\n",
      "8.0\t33.644860%\n",
      "9.0\t29.545455%\n",
      "10.0\t27.659574%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 26.128266%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.004562978369223918\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 1.0\n",
      "\n",
      "Testing of the \"Non-negative Matrix Factorization\" model successfully completed in 0:01:08.579892.\n",
      "Grid search: 0:01:06.688111\n",
      "Training and testing: 0:00:01.594693\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"Co-clustering\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'n_cltr_u': 3, 'n_cltr_i': 3, 'n_epochs': 30}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m [train = 1.3504 | test = 1.7743 ]\n",
      "\u001B[1mMAE:\u001B[22m [train = 1.0155 | test = 1.3993 ]\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 23.474178%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "2.0\t50.000000%\n",
      "5.0\t27.272727%\n",
      "6.0\t9.090909%\n",
      "7.0\t17.894737%\n",
      "8.0\t30.841121%\n",
      "9.0\t29.545455%\n",
      "10.0\t25.531915%\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 23.515439%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0049092441904994115\n",
      "\u001B[1mUser coverage (num_users=426, min_rating=4.0):\u001B[22m 0.9976525821596244\n",
      "\n",
      "Testing of the \"Co-clustering\" model successfully completed in 0:03:09.797717.\n",
      "Grid search: 0:03:08.240986\n",
      "Training and testing: 0:00:01.275005\n"
     ]
    }
   ],
   "source": [
    "print(f\"{Style.BRIGHT}Testing multiple models...{Style.RESET_ALL}\")\n",
    "model_sep = f\"{Style.DIM}{Fore.WHITE}{'=' * 25}{Style.RESET_ALL}\"\n",
    "measure_key = \"rmse\"\n",
    "models = {}\n",
    "\n",
    "for model_key in model_definitions:\n",
    "    # Initialize the model processing\n",
    "    iteration_start_time = timer()\n",
    "    model_settings = model_definitions[model_key]\n",
    "    print(f\"{model_sep}\\n{Fore.GREEN}Testing \\\"{model_settings['name']}\\\".{Fore.RESET}\")\n",
    "\n",
    "    # Train the model\n",
    "    if model_settings[\"hyper_params\"] is not None:  # If available, search the best estimator with GridSearch\n",
    "        print(f\"Running GridSearchCV...{Fore.WHITE}{Style.DIM}\")\n",
    "        grid_search_start_time = timer()\n",
    "        with io.capture_output():\n",
    "            grid_search = surprise.model_selection.GridSearchCV(\n",
    "                algo_class=model_settings[\"algo_class\"],\n",
    "                param_grid=model_settings[\"hyper_params\"],\n",
    "                measures=[\"rmse\", \"mae\"],\n",
    "                cv=data_iterator,\n",
    "                refit=False,\n",
    "                n_jobs=1,\n",
    "                joblib_verbose=0\n",
    "            )\n",
    "            grid_search.fit(data)\n",
    "\n",
    "        best_model = grid_search.best_estimator[measure_key]\n",
    "        best_params = grid_search.best_params[measure_key]\n",
    "        grid_search_end_time = timer()\n",
    "    else:\n",
    "        best_model = model_settings[\"algo_class\"]()\n",
    "        best_params = []\n",
    "        grid_search_start_time = grid_search_end_time = None\n",
    "\n",
    "    # Save the best model\n",
    "    models[model_key] = best_model\n",
    "\n",
    "    # Accuracy calculation\n",
    "    model_start_time = model_end_time = None\n",
    "    LOOCV = surprise.model_selection.LeaveOneOut(n_splits=1, min_n_ratings=1, random_state=RANDOM_STATE)\n",
    "\n",
    "    for data_train_LOOCV, data_test_LOOCV in LOOCV.split(data):\n",
    "        model_start_time = timer()\n",
    "        best_model.fit(data_train_LOOCV)\n",
    "        train_prediction = best_model.test(data_train_LOOCV.build_testset())\n",
    "        left_out_predictions = test_prediction = best_model.test(data_test_LOOCV)\n",
    "        all_predictions = best_model.test(data_train_LOOCV.build_anti_testset())\n",
    "        model_end_time = timer()\n",
    "\n",
    "        print(f\"{Style.RESET_ALL}\")\n",
    "        print(f\"{Style.BRIGHT}Best params:{Style.NORMAL} {Style.DIM}{Fore.WHITE}{best_params}{Style.RESET_ALL}\")\n",
    "        print((\n",
    "            f\"{Style.BRIGHT}RMSE:{Style.NORMAL} \"\n",
    "            f\"[ train = {surp_acc.rmse(train_prediction, verbose=False):.4f} | \"\n",
    "            f\"test = {surp_acc.rmse(test_prediction, verbose=False):.4f} ]\"\n",
    "        ))\n",
    "        print((\n",
    "            f\"{Style.BRIGHT}MAE:{Style.NORMAL} \"\n",
    "            f\"[train = {surp_acc.mae(train_prediction, verbose=False):.4f} | \"\n",
    "            f\"test = {surp_acc.mae(test_prediction, verbose=False):.4f} ]\"\n",
    "        ))\n",
    "        print(\"\")\n",
    "\n",
    "        top_n = helpers.metrics.get_top_n(predictions=all_predictions, n=10, min_rating=4.0, verbose=True)\n",
    "        helpers.metrics.get_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_rating_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_cumulative_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, min_rating=4.0, auto_print=True)\n",
    "        helpers.metrics.get_average_reciprocal_hit_rank(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_user_coverage(top_n=top_n, num_users=data_train_LOOCV.n_users, min_rating=4.0, auto_print=True)\n",
    "\n",
    "    # Save the model to the disk\n",
    "    surprise.dump.dump(file_name=str(MODELS_FOLDER / model_settings[\"name\"]), algo=best_model)\n",
    "\n",
    "    # Final output\n",
    "    iteration_end_time = timer()\n",
    "    iteration_elapsed_time = timedelta(seconds=iteration_end_time - iteration_start_time)\n",
    "    grid_search_elapsed_time = timedelta(seconds=grid_search_end_time - grid_search_start_time) if grid_search_start_time is not None else None\n",
    "    model_elapsed_time = timedelta(seconds=model_end_time - model_start_time) if model_start_time is not None else None\n",
    "    print((\n",
    "        f\"\\nTesting of the \\\"{model_settings['name']}\\\" model successfully completed in {iteration_elapsed_time}.\"\n",
    "        f\"\\nGrid search: {'N/A' if grid_search_elapsed_time is None else grid_search_elapsed_time}\"\n",
    "        f\"\\nTraining and testing: {'N/A' if model_elapsed_time is None else model_elapsed_time}\"\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
