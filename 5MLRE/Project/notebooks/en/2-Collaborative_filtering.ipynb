{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Th√©o\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Data preparation</li>\n",
    "  <li>Collaborative filtering: user-based</li>\n",
    "  <li>Collaborative filtering: item-based</li>\n",
    "  <li>Collaborative filtering: others</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "from surprise import accuracy as surp_acc\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Jupyter output\n",
    "from IPython.utils import io"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2 - Package initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3 - Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4 - Datasets loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(1, 10), skip_lines=1)\n",
    "# data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating_cleaned.csv\"), reader=data_reader)\n",
    "\n",
    "data = pandas.read_csv((DATA_FOLDER / \"rating_cleaned.csv\"))\n",
    "data_filtered = data[data[\"rating\"] >= 0.0]\n",
    "data_shortened = data.sample(n=10_000)\n",
    "\n",
    "data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(df=data_shortened, reader=data_reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## B - Data preparation\n",
    "**TODO: Add text**\n",
    "\n",
    "### B.1 - Splitting the dataset\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "data_train, data_test = surprise.model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B.2 - Choosing the data iterator\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data_iterator = surprise.model_selection.KFold(n_splits=10, random_state=RANDOM_STATE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C - Collaborative filtering\n",
    "expliquer diff. user-based/item-based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "model_definitions = {\n",
    "    \"slope_one\": {\n",
    "        \"name\": \"Slope One\",\n",
    "        \"algo_class\": surprise.SlopeOne,\n",
    "        \"hyper_params\": None\n",
    "    },\n",
    "    \"knn_basic\": {\n",
    "        \"name\": \"KNN Basic\",\n",
    "        \"algo_class\": surprise.KNNBasic,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_means\": {\n",
    "        \"name\": \"KNN With Means\",\n",
    "        \"algo_class\": surprise.KNNWithMeans,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_z-score\": {\n",
    "        \"name\": \"KNN With Z-Score\",\n",
    "        \"algo_class\": surprise.KNNWithZScore,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_baseline\": {\n",
    "        \"name\": \"KNN Baseline\",\n",
    "        \"algo_class\": surprise.KNNBaseline,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            },\n",
    "            \"bsl_options\": {\n",
    "                \"method\": [\"als\"],\n",
    "                \"n_epochs\": 10,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"non-negative_matrix_factorization\": {\n",
    "        \"name\": \"Non-negative Matrix Factorization\",\n",
    "        \"algo_class\": surprise.NMF,\n",
    "        \"hyper_params\": {\n",
    "            \"n_factors\": [5, 15, 25],\n",
    "            \"n_epochs\": [25, 50, 75],\n",
    "            \"biased\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"co-clustering\": {\n",
    "        \"name\": \"Co-clustering\",\n",
    "        \"algo_class\": surprise.CoClustering,\n",
    "        \"hyper_params\": {\n",
    "            \"n_cltr_u\": [1, 3, 5],\n",
    "            \"n_cltr_i\": [1, 3, 5],\n",
    "            \"n_epochs\": [10, 20, 30],\n",
    "        }\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mTesting multiple models...\u001B[0m\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN Basic\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 1, 'sim_options': {'name': 'cosine', 'user_based': True}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 3.7130\n",
      "\u001B[1mMAE:\u001B[22m 2.9459\n",
      "Testing of the \"KNN Basic\" model successfully completed in 0:05:12.537663.\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN With Means\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 25\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m io\u001B[38;5;241m.\u001B[39mcapture_output():\n\u001B[1;32m     16\u001B[0m     grid_search \u001B[38;5;241m=\u001B[39m surprise\u001B[38;5;241m.\u001B[39mmodel_selection\u001B[38;5;241m.\u001B[39mGridSearchCV(\n\u001B[1;32m     17\u001B[0m         algo_class\u001B[38;5;241m=\u001B[39mmodel_settings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malgo_class\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m     18\u001B[0m         param_grid\u001B[38;5;241m=\u001B[39mmodel_settings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyper_params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m         joblib_verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     24\u001B[0m     )\n\u001B[0;32m---> 25\u001B[0m     \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator[measure_key]\n\u001B[1;32m     27\u001B[0m models_user_based[model_key] \u001B[38;5;241m=\u001B[39m best_model\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/model_selection/search.py:104\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m     90\u001B[0m cv \u001B[38;5;241m=\u001B[39m get_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv)\n\u001B[1;32m     92\u001B[0m delayed_list \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     93\u001B[0m     delayed(fit_and_score)(\n\u001B[1;32m     94\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgo_class(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    102\u001B[0m     )\n\u001B[1;32m    103\u001B[0m )\n\u001B[0;32m--> 104\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoblib_verbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    110\u001B[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mout)\n\u001B[1;32m    112\u001B[0m \u001B[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001B[39;00m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/parallel.py:1051\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1049\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1051\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1054\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1055\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[1;32m   1056\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[1;32m   1057\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/parallel.py:864\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    862\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 864\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/parallel.py:782\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    780\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    781\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 782\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    783\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    784\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    569\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    570\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    571\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 572\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/joblib/parallel.py:263\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    261\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    262\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 263\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/model_selection/validation.py:173\u001B[0m, in \u001B[0;36mfit_and_score\u001B[0;34m(algo, trainset, testset, measures, return_train_measures)\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;124;03m\"\"\"Helper method that trains an algorithm and compute accuracy measures on\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;124;03ma testset. Also report train and test times.\u001B[39;00m\n\u001B[1;32m    144\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    169\u001B[0m \u001B[38;5;124;03m        - The testing time in seconds.\u001B[39;00m\n\u001B[1;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    172\u001B[0m start_fit \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 173\u001B[0m \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    174\u001B[0m fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_fit\n\u001B[1;32m    175\u001B[0m start_test \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/prediction_algorithms/knns.py:176\u001B[0m, in \u001B[0;36mKNNWithMeans.fit\u001B[0;34m(self, trainset)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainset):\n\u001B[1;32m    175\u001B[0m     SymmetricAlgo\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;28mself\u001B[39m, trainset)\n\u001B[0;32m--> 176\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_similarities\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    178\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmeans \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_x)\n\u001B[1;32m    179\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x, ratings \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mxr\u001B[38;5;241m.\u001B[39mitems():\n",
      "File \u001B[0;32m~/miniconda3/envs/5MLRE/lib/python3.10/site-packages/surprise/prediction_algorithms/algo_base.py:248\u001B[0m, in \u001B[0;36mAlgoBase.compute_similarities\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    246\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    247\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputing the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m similarity matrix...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 248\u001B[0m sim \u001B[38;5;241m=\u001B[39m \u001B[43mconstruction_func\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mverbose\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone computing similarity matrix.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"{Style.BRIGHT}Testing multiple models...{Style.RESET_ALL}\")\n",
    "model_sep = f\"{Style.DIM}{Fore.WHITE}{'=' * 25}{Style.RESET_ALL}\"\n",
    "measure_key = \"rmse\"\n",
    "best_models = {}\n",
    "\n",
    "for model_key in model_definitions:\n",
    "    # Initialize the model processing\n",
    "    model_start_time = timer()\n",
    "    model_settings = model_definitions[model_key]\n",
    "\n",
    "    print(f\"{model_sep}\\n{Fore.GREEN}Testing \\\"{model_settings['name']}\\\".{Fore.RESET}\")\n",
    "\n",
    "    # Train the model\n",
    "    if model_settings[\"hyper_params\"] is not None:  # If available, search the best estimator with GridSearch\n",
    "        print(f\"Running GridSearchCV...{Fore.WHITE}{Style.DIM}\")\n",
    "        with io.capture_output():\n",
    "            grid_search = surprise.model_selection.GridSearchCV(\n",
    "                algo_class=model_settings[\"algo_class\"],\n",
    "                param_grid=model_settings[\"hyper_params\"],\n",
    "                measures=[\"rmse\", \"mae\"],\n",
    "                cv=data_iterator,\n",
    "                refit=False,\n",
    "                n_jobs=1,\n",
    "                joblib_verbose=0\n",
    "            )\n",
    "            grid_search.fit(data)\n",
    "\n",
    "        best_model = grid_search.best_estimator[measure_key]\n",
    "    else:\n",
    "        best_model = model_definitions[\"algo_class\"]()\n",
    "\n",
    "    # Save the best model\n",
    "    best_models[model_key] = best_model\n",
    "\n",
    "    # Accuracy calculation\n",
    "    best_model.fit(data_train)\n",
    "    predictions = best_model.test(data_test)\n",
    "\n",
    "    print(f\"{Style.RESET_ALL}\")\n",
    "    print(f\"{Style.BRIGHT}Best params:{Style.NORMAL} {Style.DIM}{Fore.WHITE}{grid_search.best_params[measure_key]}{Style.RESET_ALL}\")\n",
    "    print(f\"{Style.BRIGHT}RMSE:{Style.NORMAL} {surp_acc.rmse(predictions, verbose=False):.4f}\")\n",
    "    print(f\"{Style.BRIGHT}MAE:{Style.NORMAL} {surp_acc.mae(predictions, verbose=False):.4f}\")\n",
    "\n",
    "    model_end_time = timer()\n",
    "    model_elapsed_time = timedelta(seconds=model_end_time - model_start_time)\n",
    "    print(f\"Testing of the \\\"{model_settings['name']}\\\" model successfully completed in {model_elapsed_time}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
