{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Théo\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Collaborative filtering: unfiltered training</li>\n",
    "  <li>Collaborative filtering: filtered training</li>\n",
    "  <li>Getting the Top-N</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "\n",
    "# Misc.\n",
    "from ast import literal_eval\n",
    "\n",
    "# Local files\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 - Package initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3 - Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4 - Datasets loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(-1, 10), skip_lines=1)\n",
    "data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating2.csv\"), reader=data_reader)\n",
    "\n",
    "# Load a smaller sample of the dataset instead of the 8M rows\n",
    "# data2 = pandas.read_csv((DATA_FOLDER / \"rating.csv\"), dtype={\"user_id\": str, \"anime_id\": str})\n",
    "# data = data2[data2[\"rating\"] >= 0.0]\n",
    "# data = data.sample(n=500_000)\n",
    "\n",
    "# data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "# data = surprise.Dataset.load_from_df(df=data[[\"user_id\", \"anime_id\", \"rating\"]], reader=data_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anime = pandas.read_csv(DATA_FOLDER / \"anime_cleaned.csv\", converters={\"genre_split\": literal_eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rankings = pandas.Series(data=data_anime[\"rank_num_ratings\"].values, index=data_anime[\"anime_id\"]).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing sets. This can take a while...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Building train/test sets...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Building LeaveOneOut sets...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Building full sets...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Preparing the similarities model...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "evaluator = helpers.ml.ModelEvaluator(dataset=data, rankings=rankings, models_folder=MODELS_FOLDER, seed=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B - Collaborative filtering: unfiltered training\n",
    "As we explained earlier, Collaborative filtering is a method used to make personalized recommendations by analyzing a user's past preferences or behaviors and comparing them to those of similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "- User-based: focuses on finding similar users that are looking like the target user in terms of preferences, liked items and user's navigation.\n",
    "- Item-based: focuses on finding similar items based on the user's previous interactions with other items.\n",
    "\n",
    "User-based is more relevant for entertainment-related items, as this approach would recommend items that other users with similar preferences have liked. There are a lot of parameters in terms of preference nuances. Item-based recommendations are more pertinent to online shops, which recommend products based on their characteristics. We are talking about individual tastes here.\n",
    "\n",
    "In our case, user-based filtering should give better results. But in this notebook we will test our models with both methods.\n",
    "\n",
    "## B.1 - Slope One\n",
    "Slope One is a collaborative filtering algorithm designed for recommendations. Its lightweight and simple design calculates the average difference between the user's items rating and uses this information to predict the user's potential rating on an unseen article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"Slope One\".\u001B[39m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.187853\n",
      "\u001B[1mMAE:\u001B[22m 1.397903\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 0.402010%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "10.0\t2.139037%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 0.481928%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0021775544388609714\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 100.000000%\n",
      "\u001B[1mDiversity:\u001B[22m 0.666667\n",
      "\u001B[1mNovelty:\u001B[22m 3181.175146\n",
      "\n",
      "\u001B[0mTesting of the \"Slope One\" model successfully completed in 0:08:08.516542.\n",
      "Grid search: N/A\n",
      "Training and testing: 0:00:03.649915\n",
      "Top-N building: 0:08:00.837321\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(name=\"Slope One\", model=surprise.SlopeOne, hyper_params=None, measure_key=\"rmse\", override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 - KNN Basic\n",
    "KNN Basic (K-Nearest Neighbors) is another collaborative filtering algorithm used for recommandation systems. It consists of finding the most similar \"K\" items or users based on a similarity metric. It then calculates the weighted average of the ratings of the items found to predict the user's rating for the target item or recommend items based on the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"KNN Basic\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[33mWarning: 1777260/5023288 (35.380412%) predictions were impossible! \u001B[39m\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[33mWarning: 1868184/5198312 (35.938282%) predictions were impossible! \u001B[39m\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 40, 'min_k': 1, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.220969\n",
      "\u001B[1mMAE:\u001B[22m 1.376290\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 0.402010%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "-1.0\t0.617284%\n",
      "8.0\t0.943396%\n",
      "10.0\t0.534759%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 0.361446%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0020938023450586267\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 100.000000%\n",
      "\u001B[1mDiversity:\u001B[22m 0.888889\n",
      "\u001B[1mNovelty:\u001B[22m 2921.736187\n",
      "\n",
      "\u001B[0mTesting of the \"KNN Basic\" model successfully completed in 1:05:45.386946.\n",
      "Grid search: 0:52:49.089296\n",
      "Training and testing: 0:00:06.396882\n",
      "Top-N building: 0:12:45.171156\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"KNN Basic\",\n",
    "    model=surprise.KNNBasic,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.3 - KNN With Means\n",
    "KNN With Means is a variant of the KNN Basic algorithm. This time, the algorithm adjusts the previously calculated weighted average by adding the overall average user or article rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"KNN With Means\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 40, 'min_k': 5, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.131681\n",
      "\u001B[1mMAE:\u001B[22m 1.324676\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 2.613065%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "4.0\t8.333333%\n",
      "7.0\t0.632911%\n",
      "8.0\t2.830189%\n",
      "9.0\t1.092896%\n",
      "10.0\t8.556150%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 3.132530%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.008557469889128182\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 94.673367%\n",
      "\u001B[1mDiversity:\u001B[22m 1.333333\n",
      "\u001B[1mNovelty:\u001B[22m 900.897788\n",
      "\n",
      "\u001B[0mTesting of the \"KNN With Means\" model successfully completed in 1:00:16.181467.\n",
      "Grid search: 0:55:14.867727\n",
      "Training and testing: 0:00:03.015702\n",
      "Top-N building: 0:04:53.672705\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"KNN With Means\",\n",
    "    model=surprise.KNNWithMeans,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.4 - KNN With Z-Score\n",
    "KNN With Z-Score is another variant of the KNN algorithm that takes into account the average ratings and standard deviations of users or items for predictions. In addition to the previous steps, the algorithm calculates the Z-Score by subtracting the average score and dividing the result by the standard deviation on the weighted average. With this method, this algorithm normalizes the ratings by trends and variabilities, which means better accuracy for predictions and recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"KNN With Z-Score\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 40, 'min_k': 5, 'sim_options': {'name': 'pearson_baseline', 'user_based': True}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.130252\n",
      "\u001B[1mMAE:\u001B[22m 1.299102\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 2.311558%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "7.0\t0.632911%\n",
      "8.0\t0.943396%\n",
      "9.0\t1.639344%\n",
      "10.0\t9.090909%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 2.771084%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.007682459918640822\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 98.592965%\n",
      "\u001B[1mDiversity:\u001B[22m 1.000000\n",
      "\u001B[1mNovelty:\u001B[22m 867.011802\n",
      "\n",
      "\u001B[0mTesting of the \"KNN With Z-Score\" model successfully completed in 1:04:21.438701.\n",
      "Grid search: 0:59:03.995425\n",
      "Training and testing: 0:00:03.273180\n",
      "Top-N building: 0:05:09.464974\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"KNN With Z-Score\",\n",
    "    model=surprise.KNNWithZScore,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.5 - KNN Baseline\n",
    "KNN Baseline is simpler than the previous algorithm. It calculates the distance between the raw values of the features that we want to use for our prediction. The counterpart of this method is the loss of accuracy depending to the scales or ranges of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"KNN Baseline\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'k': 20, 'min_k': 3, 'sim_options': {'name': 'pearson_baseline', 'user_based': False}, 'bsl_options': {'method': 'als', 'n_epochs': 15}}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.021351\n",
      "\u001B[1mMAE:\u001B[22m 1.246453\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 2.814070%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "-1.0\t0.617284%\n",
      "7.0\t1.265823%\n",
      "8.0\t0.943396%\n",
      "9.0\t3.825137%\n",
      "10.0\t8.556150%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 3.253012%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.008310600622158411\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 95.075377%\n",
      "\u001B[1mDiversity:\u001B[22m 0.866667\n",
      "\u001B[1mNovelty:\u001B[22m 747.497620\n",
      "\n",
      "\u001B[0mTesting of the \"KNN Baseline\" model successfully completed in 3:10:26.332287.\n",
      "Grid search: 2:57:47.466569\n",
      "Training and testing: 0:00:06.524189\n",
      "Top-N building: 0:12:27.816354\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"KNN Baseline\",\n",
    "    model=surprise.KNNBaseline,\n",
    "    hyper_params={\n",
    "        \"k\": [20, 40, 60],\n",
    "        \"min_k\": [1, 2, 3, 5],\n",
    "        \"sim_options\": {\n",
    "            \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "            \"user_based\": [True, False]\n",
    "        },\n",
    "        \"bsl_options\": {\n",
    "            \"method\": [\"als\"],\n",
    "            \"n_epochs\": [5, 10, 15],\n",
    "        }\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.6 - Non-negative Matrix Factorization\n",
    "Non-negative Matrix Factorization (NMF) is a technique used to facilitate the interpretation of non-negative matrices*¹* of data. For this, the algorithm tries to find a way to represent a non-negative matrix in smaller non-negative matrices. It can then better interpret the data structures and its predictions are improved.\n",
    "\n",
    "*1: A non-negative matrix is a matrix where all elements are greater than or equal to zero.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"Non-negative Matrix Factorization\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'n_factors': 5, 'n_epochs': 25, 'biased': True}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.542902\n",
      "\u001B[1mMAE:\u001B[22m 1.641667\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 0.301508%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "10.0\t1.604278%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 0.361446%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0018425460636515912\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 100.000000%\n",
      "\u001B[1mDiversity:\u001B[22m 0.127392\n",
      "\u001B[1mNovelty:\u001B[22m 882.962780\n",
      "\n",
      "\u001B[0mTesting of the \"Non-negative Matrix Factorization\" model successfully completed in 0:06:50.143506.\n",
      "Grid search: 0:05:08.462348\n",
      "Training and testing: 0:00:00.713953\n",
      "Top-N building: 0:01:36.056400\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"Non-negative Matrix Factorization\",\n",
    "    model=surprise.NMF,\n",
    "    hyper_params={\n",
    "        \"n_factors\": [5, 15, 25],\n",
    "        \"n_epochs\": [25, 50, 75],\n",
    "        \"biased\": [True, False]\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.7 - Co-clustering\n",
    "The goal of Co-clustering is to find a way to group similar rows and columns of a matrix, like patterns, to make them more apparent. This method is useful when working on datasets with complex row and column relationships. The algorithm will first find a correlation between the rows and columns of the dataset. It will then use the k-mean method to group the data before interpreting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mTesting \"Co-clustering\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n",
      "Computing metrics...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mCalculating the accuracy (RMSE, MAE)...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2mBuilding the top-N...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the LOOCV...\u001B[37m\u001B[2m\n",
      "\u001B[37m\u001B[2m   > Fitting on the full set...\u001B[37m\u001B[2m\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "Built top-N for each user (n=10, min_rating=3.0)\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m{'n_cltr_u': 1, 'n_cltr_i': 1, 'n_epochs': 10}\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 2.295664\n",
      "\u001B[1mMAE:\u001B[22m 1.489803\n",
      "\n",
      "\u001B[1mHit rate:\u001B[22m 2.010050%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "6.0\t1.851852%\n",
      "7.0\t0.632911%\n",
      "8.0\t1.415094%\n",
      "9.0\t2.185792%\n",
      "10.0\t5.882353%\n",
      "\u001B[1mCumulative hit rate (min_rating=3.0):\u001B[22m 2.409639%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.005360134003350083\n",
      "\u001B[1mUser coverage (num_users=995, min_rating=3.0):\u001B[22m 93.165829%\n",
      "\u001B[1mDiversity:\u001B[22m 0.977778\n",
      "\u001B[1mNovelty:\u001B[22m 2220.936524\n",
      "\n",
      "\u001B[0mTesting of the \"Co-clustering\" model successfully completed in 0:12:24.688897.\n",
      "Grid search: 0:11:08.855068\n",
      "Training and testing: 0:00:00.930792\n",
      "Top-N building: 0:01:10.142236\n"
     ]
    }
   ],
   "source": [
    "evaluator.run_model(\n",
    "    name=\"Co-clustering\",\n",
    "    model=surprise.CoClustering,\n",
    "    hyper_params={\n",
    "        \"n_cltr_u\": [1, 3, 5],\n",
    "        \"n_cltr_i\": [1, 3, 5],\n",
    "        \"n_epochs\": [10, 20, 30],\n",
    "    },\n",
    "    measure_key=\"rmse\",\n",
    "    override=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.8 - Comparing performance\n",
    "Before we compare all the previous results, let's define a few important terms that we need to understand to properly compare the performance of our models.\n",
    "\n",
    "<u>Machine Learning metrics:</u>\n",
    "- Root Mean Squared Error (RMSE): measure of the average deviation of the predicted values of the model. The lower, the better.\n",
    "- Mean Absolute Error (MAE): refers to the magnitude of difference between the prediction of an observation and the true value of that observation.\n",
    "\n",
    "<u>Recommendation systems metrics:</u>\n",
    "- Hit rate: the proportion of recommended items that are relevant to the user, expressed in percent.\n",
    "- Hit rate per rating value: is the hit rate but calculated independently for each of the possible ratings (from one to ten in our case).\n",
    "- Cumulative hit rate: is also the hit rate calculated for all rating values up to a certain threshold.\n",
    "- Average reciprocal hit rank (ARHR): is the average of the reciprocal ranks of the relevant items in the recommended list.\n",
    "- User coverage: is the proportion of users for whom the system is able to make recommendations.\n",
    "- Diversity: is the variety or dissimilarity of items recommended to users.\n",
    "- Novelty: is the degree to which recommended items are new or unexpected to the user.\n",
    "\n",
    "We can now compare our models. We are going to observe which is the best model for each metrics, and then conclude on the overall best model.\n",
    "\n",
    "The model with the most interesting metric values is the KNN Baseline due to its good performance on RMSE, MAE and hit rate. It has a reasonable training time of seven seconds. Even though the grid search takes three hours, we already have the best parameters for this model, so we don't need to run the grid search again. In another hand, KNN With Means show us an interesting performance for ARHR and a training of three seconds. KNN Basic is automatically excluded because 35% of its predictions were impossible (one of the parameters was unknown to it).\n",
    "\n",
    "Overall, based on the metrics and results we have at this moment of the training, KNN Baseline appears to be the most efficient model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D - Getting the Top-N\n",
    "The final step is to display the top-N of a user. We start by loading the previously saved top of our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "top_n_knn_baseline = helpers.ml.Model.load_top_n(filepath=(MODELS_FOLDER / \"KNN_Baseline__topN-full.pkl\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then pick a random user from our dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "263"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_user_id = int(random.choice(list(set([r[0] for r in data.raw_ratings]))))\n",
    "random_user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We define a function that build a human-readable table from the top-N."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_top_n_of(user_id: int, top_n: dict[int, list], items_df: pandas.DataFrame, auto_print: bool = False) -> pandas.DataFrame:\n",
    "    \"\"\" Returns the formatted top-N recommendation for a specific user. \"\"\"\n",
    "    user_top = []\n",
    "\n",
    "    for top_item_id, estimated_rating, _ in top_n[user_id]:\n",
    "        item = items_df[items_df[\"anime_id\"] == top_item_id].iloc[0]\n",
    "        user_top.append({\n",
    "            \"Name\": item[\"name\"],\n",
    "            \"Genre\": item[\"genre\"],\n",
    "            \"Num. ratings\": item[\"num_ratings\"],\n",
    "            \"Mean ratings\": item[\"rating\"],\n",
    "            \"User estimated rating\": estimated_rating\n",
    "        })\n",
    "\n",
    "    return pandas.DataFrame(data=user_top)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                  Name  \\\n0     Fullmetal Alchemist: Brotherhood   \n1                       Hajime no Ippo   \n2  Rainbow: Nisha Rokubou no Shichinin   \n3               Hunter x Hunter (2011)   \n4                 Clannad: After Story   \n5                              Monster   \n6             Gintama&#039;: Enchousen   \n7           Tengen Toppa Gurren Lagann   \n8              Shigatsu wa Kimi no Uso   \n9                              Clannad   \n\n                                               Genre  Num. ratings  \\\n0  Action, Adventure, Drama, Fantasy, Magic, Mili...         21494   \n1                     Comedy, Drama, Shounen, Sports          4273   \n2                Drama, Historical, Seinen, Thriller          2716   \n3            Action, Adventure, Shounen, Super Power          7477   \n4  Drama, Fantasy, Romance, Slice of Life, Supern...         15518   \n5  Drama, Horror, Mystery, Police, Psychological,...          4079   \n6  Action, Comedy, Historical, Parody, Samurai, S...          2126   \n7           Action, Adventure, Comedy, Mecha, Sci-Fi         16955   \n8             Drama, Music, Romance, School, Shounen          8271   \n9  Comedy, Drama, Romance, School, Slice of Life,...         18746   \n\n   Mean ratings  User estimated rating  \n0          9.26               9.781889  \n1          8.83               9.670955  \n2          8.64               9.654531  \n3          9.13               9.647590  \n4          9.06               9.625787  \n5          8.72               9.567637  \n6          9.11               9.521137  \n7          8.78               9.482833  \n8          8.92               9.426137  \n9          8.30               9.384167  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>Genre</th>\n      <th>Num. ratings</th>\n      <th>Mean ratings</th>\n      <th>User estimated rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Fullmetal Alchemist: Brotherhood</td>\n      <td>Action, Adventure, Drama, Fantasy, Magic, Mili...</td>\n      <td>21494</td>\n      <td>9.26</td>\n      <td>9.781889</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hajime no Ippo</td>\n      <td>Comedy, Drama, Shounen, Sports</td>\n      <td>4273</td>\n      <td>8.83</td>\n      <td>9.670955</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rainbow: Nisha Rokubou no Shichinin</td>\n      <td>Drama, Historical, Seinen, Thriller</td>\n      <td>2716</td>\n      <td>8.64</td>\n      <td>9.654531</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hunter x Hunter (2011)</td>\n      <td>Action, Adventure, Shounen, Super Power</td>\n      <td>7477</td>\n      <td>9.13</td>\n      <td>9.647590</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Clannad: After Story</td>\n      <td>Drama, Fantasy, Romance, Slice of Life, Supern...</td>\n      <td>15518</td>\n      <td>9.06</td>\n      <td>9.625787</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Monster</td>\n      <td>Drama, Horror, Mystery, Police, Psychological,...</td>\n      <td>4079</td>\n      <td>8.72</td>\n      <td>9.567637</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Gintama&amp;#039;: Enchousen</td>\n      <td>Action, Comedy, Historical, Parody, Samurai, S...</td>\n      <td>2126</td>\n      <td>9.11</td>\n      <td>9.521137</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Tengen Toppa Gurren Lagann</td>\n      <td>Action, Adventure, Comedy, Mecha, Sci-Fi</td>\n      <td>16955</td>\n      <td>8.78</td>\n      <td>9.482833</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Shigatsu wa Kimi no Uso</td>\n      <td>Drama, Music, Romance, School, Shounen</td>\n      <td>8271</td>\n      <td>8.92</td>\n      <td>9.426137</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Clannad</td>\n      <td>Comedy, Drama, Romance, School, Slice of Life,...</td>\n      <td>18746</td>\n      <td>8.30</td>\n      <td>9.384167</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_of(user_id=random_user_id, top_n=top_n_knn_baseline, items_df=data_anime, auto_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is the top-10 of the randomly selected user."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## E - Conclusion of the collaborative filtering\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
