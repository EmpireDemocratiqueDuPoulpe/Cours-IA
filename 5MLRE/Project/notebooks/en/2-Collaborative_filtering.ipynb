{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## School project - 5MLRE\n",
    "The following notebook was created for a school project to create an anime recommendation system. The subject and the questions are available in the appendix.\n",
    "\n",
    "The group members who participated in this project are:\n",
    "- AMIMI Lamine\n",
    "- BEZIN Th√©o\n",
    "- LECOMTE Alexis\n",
    "- PAWLOWSKI Maxence\n",
    "\n",
    "### Main index\n",
    "1. Data analysis\n",
    "2. **Collaborative filtering (you are here)**\n",
    "3. Content-based filtering\n",
    "4. _Appendix_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 - Collaborative filtering\n",
    "In the previous notebook, we loaded, cleaned and studied the [MyAnimeList](https://myanimelist.net/) datasets. Now that we know them better, we will start to create the recommendation system using collaborative filtering. Collaborative filtering is a technique that filters out items that a user might like based on feedback from similar users. There are two sub-techniques: User-based collaborative filtering and article-based collaborative filtering.\n",
    "\n",
    "### Index\n",
    "<ol type=\"A\">\n",
    "  <li>Notebook initialization</li>\n",
    "  <li>Data preparation</li>\n",
    "  <li>Collaborative filtering: user-based</li>\n",
    "  <li>Collaborative filtering: item-based</li>\n",
    "  <li>Collaborative filtering: others</li>\n",
    "  <li>Conclusion of the collaborative filtering</li>\n",
    "</ol>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## A - Notebook initialization\n",
    "### A.1 - Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "from matplotlib import pyplot\n",
    "import matplotx\n",
    "\n",
    "# Model processing\n",
    "import surprise\n",
    "from surprise import accuracy as surp_acc\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore, Style\n",
    "\n",
    "# Jupyter output\n",
    "from IPython.utils import io\n",
    "\n",
    "# Local files\n",
    "sys.path.append(os.path.join(os.pardir, os.pardir))\n",
    "import helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.2 - Package initialization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "pyplot.rcParams.update(pyplot.rcParamsDefault)\n",
    "pyplot.style.use(matplotx.styles.dracula)  # Set the matplotlib style"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.3 - Constants"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Filesystem paths\n",
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"data\").resolve()\n",
    "MODELS_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"models\").resolve()\n",
    "TEMP_FOLDER = (PARENT_FOLDER / \"..\" / \"..\" / \"temp\").resolve()\n",
    "\n",
    "# Plots\n",
    "FIG_SIZE = (12, 7)\n",
    "\n",
    "# Misc.\n",
    "RANDOM_STATE = 2077"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A.4 - Datasets loading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data_reader = surprise.Reader(line_format=\"user item rating\", sep=\",\", rating_scale=(1, 10), skip_lines=1)\n",
    "# data = surprise.Dataset.load_from_file(file_path=(DATA_FOLDER / \"rating_cleaned.csv\"), reader=data_reader)\n",
    "\n",
    "data_cleaned = pandas.read_csv((DATA_FOLDER / \"rating_cleaned.csv\"))\n",
    "data_filtered = data_cleaned[data_cleaned[\"rating\"] >= 0.0]\n",
    "data_shortened = data_filtered.sample(n=5000)\n",
    "\n",
    "data_reader = surprise.Reader(rating_scale=(1, 10))\n",
    "data = surprise.Dataset.load_from_df(df=data_shortened[[\"user_id\", \"anime_id\", \"rating\"]], reader=data_reader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# B - Data preparation\n",
    "**TODO: Add text**\n",
    "\n",
    "### B.1 - Splitting the dataset\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# data_train, data_test = surprise.model_selection.train_test_split(data, test_size=0.2, shuffle=True, random_state=RANDOM_STATE)\n",
    "\"\"\"data_train_full = data.build_full_trainset()\n",
    "data_test = data_train_full.build_testset()\n",
    "data_anti_test = data_train_full.build_anti_testset()\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### B.2 - Choosing the data iterator\n",
    "**TODO: Add text**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_iterator = surprise.model_selection.KFold(n_splits=10, random_state=RANDOM_STATE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# C - Collaborative filtering\n",
    "expliquer diff. user-based/item-based"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model_definitions = {\n",
    "    \"slope_one\": {\n",
    "        \"name\": \"Slope One\",\n",
    "        \"algo_class\": surprise.SlopeOne,\n",
    "        \"hyper_params\": None\n",
    "    },\n",
    "    \"knn_basic\": {\n",
    "        \"name\": \"KNN Basic\",\n",
    "        \"algo_class\": surprise.KNNBasic,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_means\": {\n",
    "        \"name\": \"KNN With Means\",\n",
    "        \"algo_class\": surprise.KNNWithMeans,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_with_z-score\": {\n",
    "        \"name\": \"KNN With Z-Score\",\n",
    "        \"algo_class\": surprise.KNNWithZScore,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"knn_baseline\": {\n",
    "        \"name\": \"KNN Baseline\",\n",
    "        \"algo_class\": surprise.KNNBaseline,\n",
    "        \"hyper_params\": {\n",
    "            \"k\": [20, 40, 60],\n",
    "            \"min_k\": [1, 2, 3, 5],\n",
    "            \"sim_options\": {\n",
    "                \"name\": [\"cosine\", \"msd\", \"pearson\", \"pearson_baseline\"],\n",
    "                \"user_based\": [True, False]\n",
    "            },\n",
    "            \"bsl_options\": {\n",
    "                \"method\": [\"als\"],\n",
    "                \"n_epochs\": [5, 10, 15],\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"non-negative_matrix_factorization\": {\n",
    "        \"name\": \"Non-negative Matrix Factorization\",\n",
    "        \"algo_class\": surprise.NMF,\n",
    "        \"hyper_params\": {\n",
    "            \"n_factors\": [5, 15, 25],\n",
    "            \"n_epochs\": [25, 50, 75],\n",
    "            \"biased\": [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"co-clustering\": {\n",
    "        \"name\": \"Co-clustering\",\n",
    "        \"algo_class\": surprise.CoClustering,\n",
    "        \"hyper_params\": {\n",
    "            \"n_cltr_u\": [1, 3, 5],\n",
    "            \"n_cltr_i\": [1, 3, 5],\n",
    "            \"n_epochs\": [10, 20, 30],\n",
    "        }\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mTesting multiple models...\u001B[0m\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"Slope One\".\u001B[39m\n",
      "\u001B[0m\n",
      "\u001B[1mBest params:\u001B[22m \u001B[2m\u001B[37m[]\u001B[0m\n",
      "\u001B[1mRMSE:\u001B[22m 0.8767\n",
      "\u001B[1mMAE:\u001B[22m 0.3841\n",
      "\n",
      "Built top-N for each user (n=10, min_rating=4.0)\n",
      "\u001B[1mHit rate:\u001B[22m 0.0000%\n",
      "\u001B[1mHit rate per rating value:\u001B[22m\n",
      "Rating\tHit rate\n",
      "\u001B[1mCumulative hit rate (min_rating=4.0):\u001B[22m 0.0000%\n",
      "\u001B[1mAverage reciprocal hit rate:\u001B[22m 0.0\n",
      "\u001B[1mUser coverage (num_users=8356, min_rating=4.0):\u001B[22m 0.8264719961704164\n",
      "Testing of the \"Slope One\" model successfully completed in 0:02:42.243308.Grid search: N/ATraining and testing: 0:02:05.960225\n",
      "\u001B[2m\u001B[37m=========================\u001B[0m\n",
      "\u001B[32mTesting \"KNN Basic\".\u001B[39m\n",
      "Running GridSearchCV...\u001B[37m\u001B[2m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 27\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m io\u001B[38;5;241m.\u001B[39mcapture_output():\n\u001B[0;32m     18\u001B[0m     grid_search \u001B[38;5;241m=\u001B[39m surprise\u001B[38;5;241m.\u001B[39mmodel_selection\u001B[38;5;241m.\u001B[39mGridSearchCV(\n\u001B[0;32m     19\u001B[0m         algo_class\u001B[38;5;241m=\u001B[39mmodel_settings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malgo_class\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m     20\u001B[0m         param_grid\u001B[38;5;241m=\u001B[39mmodel_settings[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyper_params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     25\u001B[0m         joblib_verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     26\u001B[0m     )\n\u001B[1;32m---> 27\u001B[0m     \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     29\u001B[0m best_model \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_estimator[measure_key]\n\u001B[0;32m     30\u001B[0m best_params \u001B[38;5;241m=\u001B[39m grid_search\u001B[38;5;241m.\u001B[39mbest_params[measure_key]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\surprise\\model_selection\\search.py:104\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     90\u001B[0m cv \u001B[38;5;241m=\u001B[39m get_cv(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv)\n\u001B[0;32m     92\u001B[0m delayed_list \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     93\u001B[0m     delayed(fit_and_score)(\n\u001B[0;32m     94\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgo_class(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    102\u001B[0m     )\n\u001B[0;32m    103\u001B[0m )\n\u001B[1;32m--> 104\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    106\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpre_dispatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpre_dispatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    107\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoblib_verbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    108\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelayed_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mout)\n\u001B[0;32m    112\u001B[0m \u001B[38;5;66;03m# test_measures_dicts is a list of dict like this:\u001B[39;00m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# [{'mae': 1, 'rmse': 2}, {'mae': 2, 'rmse': 3} ...]\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# E.g. for 5 splits, the first 5 dicts are for the first param\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# (n_parameters_combinations, n_splits). This way we can easily compute\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# the mean and std dev over all splits or over all param comb.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[0;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\surprise\\model_selection\\validation.py:173\u001B[0m, in \u001B[0;36mfit_and_score\u001B[1;34m(algo, trainset, testset, measures, return_train_measures)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Helper method that trains an algorithm and compute accuracy measures on\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;124;03ma testset. Also report train and test times.\u001B[39;00m\n\u001B[0;32m    144\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    169\u001B[0m \u001B[38;5;124;03m        - The testing time in seconds.\u001B[39;00m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    172\u001B[0m start_fit \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m--> 173\u001B[0m \u001B[43malgo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrainset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    174\u001B[0m fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_fit\n\u001B[0;32m    175\u001B[0m start_test \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\surprise\\prediction_algorithms\\knns.py:98\u001B[0m, in \u001B[0;36mKNNBasic.fit\u001B[1;34m(self, trainset)\u001B[0m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, trainset):\n\u001B[0;32m     97\u001B[0m     SymmetricAlgo\u001B[38;5;241m.\u001B[39mfit(\u001B[38;5;28mself\u001B[39m, trainset)\n\u001B[1;32m---> 98\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msim \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_similarities\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\5MLRE\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:249\u001B[0m, in \u001B[0;36mAlgoBase.compute_similarities\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputing the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m similarity matrix...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    248\u001B[0m sim \u001B[38;5;241m=\u001B[39m construction_func[name](\u001B[38;5;241m*\u001B[39margs)\n\u001B[1;32m--> 249\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mverbose\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m:\n\u001B[0;32m    250\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone computing similarity matrix.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sim\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "print(f\"{Style.BRIGHT}Testing multiple models...{Style.RESET_ALL}\")\n",
    "model_sep = f\"{Style.DIM}{Fore.WHITE}{'=' * 25}{Style.RESET_ALL}\"\n",
    "measure_key = \"rmse\"\n",
    "best_models = {}\n",
    "\n",
    "for model_key in model_definitions:\n",
    "    # Initialize the model processing\n",
    "    iteration_start_time = timer()\n",
    "    model_settings = model_definitions[model_key]\n",
    "    print(f\"{model_sep}\\n{Fore.GREEN}Testing \\\"{model_settings['name']}\\\".{Fore.RESET}\")\n",
    "\n",
    "    # Train the model\n",
    "    if model_settings[\"hyper_params\"] is not None:  # If available, search the best estimator with GridSearch\n",
    "        print(f\"Running GridSearchCV...{Fore.WHITE}{Style.DIM}\")\n",
    "        grid_search_start_time = timer()\n",
    "        with io.capture_output():\n",
    "            grid_search = surprise.model_selection.GridSearchCV(\n",
    "                algo_class=model_settings[\"algo_class\"],\n",
    "                param_grid=model_settings[\"hyper_params\"],\n",
    "                measures=[\"rmse\", \"mae\"],\n",
    "                cv=data_iterator,\n",
    "                refit=False,\n",
    "                n_jobs=1,\n",
    "                joblib_verbose=0\n",
    "            )\n",
    "            grid_search.fit(data)\n",
    "\n",
    "        best_model = grid_search.best_estimator[measure_key]\n",
    "        best_params = grid_search.best_params[measure_key]\n",
    "        grid_search_end_time = timer()\n",
    "    else:\n",
    "        best_model = model_settings[\"algo_class\"]()\n",
    "        best_params = []\n",
    "        grid_search_start_time = grid_search_end_time = None\n",
    "\n",
    "    # Save the best model\n",
    "    best_models[model_key] = best_model\n",
    "\n",
    "    # Accuracy calculation\n",
    "    model_start_time = model_end_time = None\n",
    "    LOOCV = surprise.model_selection.LeaveOneOut(n_splits=1, min_n_ratings=1, random_state=RANDOM_STATE)\n",
    "\n",
    "    for data_train_LOOCV, data_test_LOOCV in LOOCV.split(data):\n",
    "        model_start_time = timer()\n",
    "        best_models.fit(data_train_LOOCV)\n",
    "        train_prediction = best_models.test(data_train_LOOCV.build_testset())\n",
    "        left_out_predictions = test_prediction = best_models.test(data_test_LOOCV)\n",
    "        all_predictions = best_models.test(data_train_LOOCV.build_anti_testset())\n",
    "        model_end_time = timer()\n",
    "\n",
    "        print(f\"{Style.RESET_ALL}\")\n",
    "        print(f\"{Style.BRIGHT}Best params:{Style.NORMAL} {Style.DIM}{Fore.WHITE}{best_params}{Style.RESET_ALL}\")\n",
    "        print((\n",
    "            f\"{Style.BRIGHT}RMSE:{Style.NORMAL} \"\n",
    "            f\"[train = {surp_acc.rmse(train_prediction, verbose=False):.4f} | \"\n",
    "            f\"test = {surp_acc.rmse(test_prediction, verbose=False):.4f} ]\"\n",
    "        ))\n",
    "        print((\n",
    "            f\"{Style.BRIGHT}MAE:{Style.NORMAL} \"\n",
    "            f\"[train = {surp_acc.mae(train_prediction, verbose=False):.4f} | \"\n",
    "            f\"test = {surp_acc.mae(test_prediction, verbose=False):.4f} ]\"\n",
    "        ))\n",
    "        print(\"\")\n",
    "\n",
    "        top_n = helpers.metrics.get_top_n(predictions=all_predictions, n=10, min_rating=4.0, verbose=True)\n",
    "        helpers.metrics.get_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_rating_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_cumulative_hit_rate(top_n=top_n, left_out_predictions=left_out_predictions, min_rating=4.0, auto_print=True)\n",
    "        helpers.metrics.get_average_reciprocal_hit_rank(top_n=top_n, left_out_predictions=left_out_predictions, auto_print=True)\n",
    "        helpers.metrics.get_user_coverage(top_n=top_n, num_users=data_train_LOOCV.n_users, min_rating=4.0, auto_print=True)\n",
    "\n",
    "    # Final output\n",
    "    iteration_end_time = timer()\n",
    "    iteration_elapsed_time = timedelta(seconds=iteration_end_time - iteration_start_time)\n",
    "    grid_search_elapsed_time = timedelta(seconds=grid_search_end_time - grid_search_start_time) if grid_search_start_time is not None else None\n",
    "    model_elapsed_time = timedelta(seconds=model_end_time - model_start_time) if model_start_time is not None else None\n",
    "    print((\n",
    "        f\"\\nTesting of the \\\"{model_settings['name']}\\\" model successfully completed in {iteration_elapsed_time}.\"\n",
    "        f\"\\nGrid search: {'N/A' if grid_search_elapsed_time is None else grid_search_elapsed_time}\"\n",
    "        f\"\\nTraining and testing: {'N/A' if model_elapsed_time is None else model_elapsed_time}\"\n",
    "    ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
