{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 5DEEP - Projet\n",
    "As stated on the [dataset website](https://urbansounddataset.weebly.com/urbansound8k.html), the dataset contains 8,732 labeled excerpts of up to four seconds in length. These sounds were recorded in an urban area and are classified into ten classes:\n",
    "\n",
    "- Air conditioner\n",
    "- Car horn\n",
    "- Children playing\n",
    "- Dog barking\n",
    "- Drilling\n",
    "- Engine idling\n",
    "- Gun shot\n",
    "- Jackhammer\n",
    "- Siren\n",
    "- Street music\n",
    "\n",
    "All excerpts were downloaded from [www.freesound.org](https://www.freesound.org) and presorted into ten folds. An additional CSV file containing metadata about each extract is also provided.\n",
    "\n",
    "## Rules to follow\n",
    "The provider of the dataset has set certain ground rules that must be followed. This is necessary to ensure that our model is comparable to all other research done on this dataset.\n",
    "\n",
    "1. **The data should not be reshuffled.** Reshuffling can inflate the model scores and flaw the performance of our model.\n",
    "2. **The data should be evaluated using \"10-fold cross-validation\".** Each of the folds has different levels of classification difficulty for the model. Using another technique may also lead to inflated scores and incorrect results.\n",
    "\n",
    "\n",
    "## Imports\n",
    "Here we import all used packages. This prevents some imports from being hidden in another piece of code and ensures that nothing is imported twice."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OS and filesystem\n",
    "from pathlib import Path\n",
    "\n",
    "# Data\n",
    "import pandas\n",
    "\n",
    "# Console output\n",
    "from colorama import Fore, Style\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Constants\n",
    "We also define some constants used in this notebook. Be careful when you change these constants."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "PARENT_FOLDER = Path.cwd()\n",
    "DATA_FOLDER = PARENT_FOLDER / \"..\" / \"data\"\n",
    "URBAN_DATASET_FOLDER = DATA_FOLDER / \"UrbanSound8K\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset initialization\n",
    "We load the CSV file provided with the dataset, and perform a simple check to ensure that each file is present in the correct folder."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n\n              class  \n0          dog_bark  \n1  children_playing  \n2  children_playing  \n3  children_playing  \n4  children_playing  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>slice_file_name</th>\n      <th>fsID</th>\n      <th>start</th>\n      <th>end</th>\n      <th>salience</th>\n      <th>fold</th>\n      <th>classID</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>100032-3-0-0.wav</td>\n      <td>100032</td>\n      <td>0.0</td>\n      <td>0.317551</td>\n      <td>1</td>\n      <td>5</td>\n      <td>3</td>\n      <td>dog_bark</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100263-2-0-117.wav</td>\n      <td>100263</td>\n      <td>58.5</td>\n      <td>62.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>100263-2-0-121.wav</td>\n      <td>100263</td>\n      <td>60.5</td>\n      <td>64.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>100263-2-0-126.wav</td>\n      <td>100263</td>\n      <td>63.0</td>\n      <td>67.000000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100263-2-0-137.wav</td>\n      <td>100263</td>\n      <td>68.5</td>\n      <td>72.500000</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>children_playing</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pandas.read_csv(URBAN_DATASET_FOLDER / \"metadata\" / \"UrbanSound8K.csv\")\n",
    "data.head(n=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Checking the dataset integrity...:   0%|          | 0/8732 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49ef44d16b8d49f6835fee294231c2ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mSuccessful verification of the dataset. No missing files were detected.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "missing_files_count = 0\n",
    "\n",
    "for index, row in tqdm(data.iterrows(), total=data.shape[0], desc=\"Checking the dataset integrity...\"):\n",
    "    file_path = URBAN_DATASET_FOLDER / \"audio\" / f\"fold{row['fold']}\" / row[\"slice_file_name\"]\n",
    "\n",
    "    if not file_path.is_file():\n",
    "        missing_files_count += 1\n",
    "        print(f\"{Style.DIM}{Fore.WHITE}Missing file at \\\"{file_path}\\\"{Style.RESET_ALL}\")\n",
    "\n",
    "if missing_files_count == 0:\n",
    "    print(f\"{Fore.GREEN}Successful verification of the dataset. No missing files were detected.{Style.RESET_ALL}\")\n",
    "else:\n",
    "    print(f\"{Fore.YELLOW}Successful verification of the dataset. {missing_files_count} file{'s are ' if missing_files_count > 1 else ' is '} missing. You should consider re-downloading the dataset.{Style.RESET_ALL}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Terminology\n",
    "Before we go any further, let's define some words we will use in this notebook.\n",
    "\n",
    "- **Frequency:** The number of occurrences of a repeating event per unit of time. The frequency is measured in hertz (Hz) which is equal to one event per second.\n",
    "- **Audio frequency:** A periodic vibration whose *frequency* is audible to the average human. Like the *frequency*, the SI unit is the hertz (Hz). It is the property of sound that most determines pitch.\n",
    "- **Amplitude:** The amplitude of a periodic variable is a measure of its change in a single unit of time (period).\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Sine_voltage.svg/600px-Sine_voltage.svg.png\" width=\"250\">\n",
    "    _1. Peak amplitude ($รป$)_\n",
    "    _2. Peak-to-peak amplitude ($2รป$)_\n",
    "    _3. Root mean square amplitude ($รป/\\sqrt{2}$)_\n",
    "    _4. Wave period (not an amplitude)_\n",
    "- **Channels:** An audio channel is an audio source. The number of channels determines the type of audio file:\n",
    "    - <u>Monophonic sound reproduction (mono):</u> A sound intended to be heard as if it were emanating from one position. Monaural sound has largely been replaced by *stereo* sound, but remains the standard for radiotelephone communications, telephone networks and audio induction loops for use with hearing aids.\n",
    "    - <u>Stereophonic sound (stereo):</u> A method that recreates a multi-directional, 3-dimensional audible perspective. This is usually achieved by using two independent audio channels through a configuration of two speakers in a such way as to create the impression of sound heard from various directions, as in natural hearing.\n",
    "    - <u>Surround sound:</u> A technique for enriching the fidelity and depth of sound reproduction by using multiple audio channels from speakers. This term is often used for systems that use more than two audio channels, such as movie theaters that use a 16.2 surround system.\n",
    "- **Sample:** A sample is a value of the signal at a point in time and/or space.\n",
    "- **Sampling rate:** The average number of samples obtained in one second, thus $f_{s} = 1/T$. Like the *frequency*, the SI unit is the hertz (Hz). The sampling rate used on most TVs is 48 kHz, which means 48,000 *samples* per second."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
